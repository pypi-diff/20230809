# Comparing `tmp/cumm_cu120-0.4.8-cp39-cp39-win_amd64.whl.zip` & `tmp/cumm_cu120-0.4.9-cp39-cp39-win_amd64.whl.zip`

## zipinfo {}

```diff
@@ -1,219 +1,219 @@
-Zip file size: 1101135 bytes, number of entries: 217
--rw-rw-rw-  2.0 fat     1340 b- defN 23-Mar-29 08:36 cumm/__init__.py
--rw-rw-rw-  2.0 fat       23 b- defN 23-Mar-29 08:55 cumm/__version__.py
--rw-rw-rw-  2.0 fat    27857 b- defN 23-Mar-29 08:36 cumm/common.py
--rw-rw-rw-  2.0 fat     1764 b- defN 23-Mar-29 08:36 cumm/constants.py
--rw-rw-rw-  2.0 fat  1045504 b- defN 23-Mar-29 08:56 cumm/core_cc.cp39-win_amd64.pyd
--rw-rw-rw-  2.0 fat     5888 b- defN 23-Mar-29 08:36 cumm/dtypes.py
--rw-rw-rw-  2.0 fat     6575 b- defN 23-Mar-29 08:36 cumm/inliner.py
--rw-rw-rw-  2.0 fat    41030 b- defN 23-Mar-29 08:36 cumm/tensorview_bind.py
--rw-rw-rw-  2.0 fat    18470 b- defN 23-Mar-29 08:36 cumm/tensorview_bind_anno.pyi
--rw-rw-rw-  2.0 fat      589 b- defN 23-Mar-29 08:36 cumm/cmds/__init__.py
--rw-rw-rw-  2.0 fat      589 b- defN 23-Mar-29 08:36 cumm/cmds/include_path/__init__.py
--rw-rw-rw-  2.0 fat      121 b- defN 23-Mar-29 08:36 cumm/cmds/include_path/__main__.py
--rw-rw-rw-  2.0 fat      584 b- defN 23-Mar-29 08:36 cumm/conv/__init__.py
--rw-rw-rw-  2.0 fat     3125 b- defN 23-Mar-29 08:36 cumm/conv/algo.py
--rw-rw-rw-  2.0 fat     3634 b- defN 23-Mar-29 08:36 cumm/conv/bases.py
--rw-rw-rw-  2.0 fat   123453 b- defN 23-Mar-29 08:36 cumm/conv/input_iters.py
--rw-rw-rw-  2.0 fat    63083 b- defN 23-Mar-29 08:36 cumm/conv/kernel.py
--rw-rw-rw-  2.0 fat    68276 b- defN 23-Mar-29 08:36 cumm/conv/main.py
--rw-rw-rw-  2.0 fat    22169 b- defN 23-Mar-29 08:36 cumm/conv/main_real.py
--rw-rw-rw-  2.0 fat    19016 b- defN 23-Mar-29 08:36 cumm/conv/main_real_spconv.py
--rw-rw-rw-  2.0 fat    17968 b- defN 23-Mar-29 08:36 cumm/conv/nvrtc_code.py
--rw-rw-rw-  2.0 fat    18947 b- defN 23-Mar-29 08:36 cumm/conv/params.py
--rw-rw-rw-  2.0 fat    50736 b- defN 23-Mar-29 08:36 cumm/conv/sparse_iters.py
--rw-rw-rw-  2.0 fat      690 b- defN 23-Mar-29 08:36 cumm/conv/algospec/__init__.py
--rw-rw-rw-  2.0 fat     1263 b- defN 23-Mar-29 08:36 cumm/conv/algospec/all.py
--rw-rw-rw-  2.0 fat      734 b- defN 23-Mar-29 08:36 cumm/conv/algospec/core.py
--rw-rw-rw-  2.0 fat    10008 b- defN 23-Mar-29 08:36 cumm/conv/algospec/simt.py
--rw-rw-rw-  2.0 fat    12175 b- defN 23-Mar-29 08:36 cumm/conv/algospec/turing.py
--rw-rw-rw-  2.0 fat    10372 b- defN 23-Mar-29 08:36 cumm/conv/algospec/volta.py
--rw-rw-rw-  2.0 fat        0 b- defN 23-Mar-29 08:55 cumm/core_cc/__init__.pyi
--rw-rw-rw-  2.0 fat    18683 b- defN 23-Mar-29 08:55 cumm/core_cc/tensorview_bind.pyi
--rw-rw-rw-  2.0 fat        0 b- defN 23-Mar-29 08:55 cumm/core_cc/csrc/__init__.pyi
--rw-rw-rw-  2.0 fat     2888 b- defN 23-Mar-29 08:55 cumm/core_cc/csrc/arrayref.pyi
--rw-rw-rw-  2.0 fat      584 b- defN 23-Mar-29 08:36 cumm/csrc/__init__.py
--rw-rw-rw-  2.0 fat    17946 b- defN 23-Mar-29 08:36 cumm/csrc/arrayref.py
--rw-rw-rw-  2.0 fat     8173 b- defN 23-Mar-29 08:36 cumm/cudasim/__init__.py
--rw-rw-rw-  2.0 fat     1668 b- defN 23-Mar-29 08:36 cumm/cudasim/checkers.py
--rw-rw-rw-  2.0 fat     1679 b- defN 23-Mar-29 08:36 cumm/cudasim/debug.py
--rw-rw-rw-  2.0 fat      589 b- defN 23-Mar-29 08:36 cumm/devapps/__init__.py
--rw-rw-rw-  2.0 fat     2925 b- defN 23-Mar-29 08:36 cumm/devapps/template.py
--rw-rw-rw-  2.0 fat      589 b- defN 23-Mar-29 08:36 cumm/develop/__init__.py
--rw-rw-rw-  2.0 fat     3149 b- defN 23-Mar-29 08:36 cumm/develop/eigendev.py
--rw-rw-rw-  2.0 fat     6945 b- defN 23-Mar-29 08:36 cumm/develop/mathgen.py
--rw-rw-rw-  2.0 fat      613 b- defN 23-Mar-29 08:36 cumm/gemm/__init__.py
--rw-rw-rw-  2.0 fat    10838 b- defN 23-Mar-29 08:36 cumm/gemm/bases.py
--rw-rw-rw-  2.0 fat     3116 b- defN 23-Mar-29 08:36 cumm/gemm/codeops.py
--rw-rw-rw-  2.0 fat     2082 b- defN 23-Mar-29 08:36 cumm/gemm/constants.py
--rw-rw-rw-  2.0 fat    13157 b- defN 23-Mar-29 08:36 cumm/gemm/cutlasstest.py
--rw-rw-rw-  2.0 fat     3121 b- defN 23-Mar-29 08:36 cumm/gemm/dev_gemm.py
--rw-rw-rw-  2.0 fat    25132 b- defN 23-Mar-29 08:36 cumm/gemm/gather.py
--rw-rw-rw-  2.0 fat    54527 b- defN 23-Mar-29 08:36 cumm/gemm/kernel.py
--rw-rw-rw-  2.0 fat    26748 b- defN 23-Mar-29 08:36 cumm/gemm/layout.py
--rw-rw-rw-  2.0 fat    30873 b- defN 23-Mar-29 08:36 cumm/gemm/layout_tensorop.py
--rw-rw-rw-  2.0 fat    87853 b- defN 23-Mar-29 08:36 cumm/gemm/main.py
--rw-rw-rw-  2.0 fat     3722 b- defN 23-Mar-29 08:36 cumm/gemm/main_profile.py
--rw-rw-rw-  2.0 fat    34988 b- defN 23-Mar-29 08:36 cumm/gemm/main_real.py
--rw-rw-rw-  2.0 fat    11527 b- defN 23-Mar-29 08:36 cumm/gemm/main_real_test.py
--rw-rw-rw-  2.0 fat    33776 b- defN 23-Mar-29 08:36 cumm/gemm/main_simu.py
--rw-rw-rw-  2.0 fat     7417 b- defN 23-Mar-29 08:36 cumm/gemm/mask.py
--rw-rw-rw-  2.0 fat    74834 b- defN 23-Mar-29 08:36 cumm/gemm/mask_iters.py
--rw-rw-rw-  2.0 fat    13730 b- defN 23-Mar-29 08:36 cumm/gemm/nvrtc_code.py
--rw-rw-rw-  2.0 fat    44487 b- defN 23-Mar-29 08:36 cumm/gemm/out_iters.py
--rw-rw-rw-  2.0 fat      584 b- defN 23-Mar-29 08:36 cumm/gemm/output.py
--rw-rw-rw-  2.0 fat    23481 b- defN 23-Mar-29 08:36 cumm/gemm/thread_map.py
--rw-rw-rw-  2.0 fat    76058 b- defN 23-Mar-29 08:36 cumm/gemm/turing_iters.py
--rw-rw-rw-  2.0 fat    85772 b- defN 23-Mar-29 08:36 cumm/gemm/turing_my_iters.py
--rw-rw-rw-  2.0 fat    39273 b- defN 23-Mar-29 08:36 cumm/gemm/turing_out_iters.py
--rw-rw-rw-  2.0 fat     3704 b- defN 23-Mar-29 08:36 cumm/gemm/utils.py
--rw-rw-rw-  2.0 fat    40533 b- defN 23-Mar-29 08:36 cumm/gemm/volta_iters.py
--rw-rw-rw-  2.0 fat    20364 b- defN 23-Mar-29 08:36 cumm/gemm/volta_out_iters.py
--rw-rw-rw-  2.0 fat      802 b- defN 23-Mar-29 08:36 cumm/gemm/algospec/__init__.py
--rw-rw-rw-  2.0 fat     1303 b- defN 23-Mar-29 08:36 cumm/gemm/algospec/all.py
--rw-rw-rw-  2.0 fat     5349 b- defN 23-Mar-29 08:36 cumm/gemm/algospec/bases.py
--rw-rw-rw-  2.0 fat     3408 b- defN 23-Mar-29 08:36 cumm/gemm/algospec/core.py
--rw-rw-rw-  2.0 fat    20980 b- defN 23-Mar-29 08:36 cumm/gemm/algospec/simt.py
--rw-rw-rw-  2.0 fat    24737 b- defN 23-Mar-29 08:36 cumm/gemm/algospec/turing.py
--rw-rw-rw-  2.0 fat    17206 b- defN 23-Mar-29 08:36 cumm/gemm/algospec/volta.py
--rw-rw-rw-  2.0 fat      610 b- defN 23-Mar-29 08:36 cumm/gemm/arch/__init__.py
--rw-rw-rw-  2.0 fat    10848 b- defN 23-Mar-29 08:36 cumm/gemm/arch/cpasync.py
--rw-rw-rw-  2.0 fat     9819 b- defN 23-Mar-29 08:36 cumm/gemm/arch/instmma.py
--rw-rw-rw-  2.0 fat     4438 b- defN 23-Mar-29 08:36 cumm/gemm/arch/ldmatrix.py
--rw-rw-rw-  2.0 fat     4201 b- defN 23-Mar-29 08:36 cumm/gemm/arch/memory.py
--rw-rw-rw-  2.0 fat    32651 b- defN 23-Mar-29 08:36 cumm/gemm/arch/tensorop.py
--rw-rw-rw-  2.0 fat      693 b- defN 23-Mar-29 08:36 cumm/gemm/blockmma/__init__.py
--rw-rw-rw-  2.0 fat    61187 b- defN 23-Mar-29 08:36 cumm/gemm/blockmma/mma.py
--rw-rw-rw-  2.0 fat     4737 b- defN 23-Mar-29 08:36 cumm/gemm/blockmma/mma_async.py
--rw-rw-rw-  2.0 fat    58734 b- defN 23-Mar-29 08:36 cumm/gemm/blockmma/mma_multistage.py
--rw-rw-rw-  2.0 fat     1207 b- defN 23-Mar-29 08:36 cumm/gemm/core/__init__.py
--rw-rw-rw-  2.0 fat     4194 b- defN 23-Mar-29 08:36 cumm/gemm/core/metaarray.py
--rw-rw-rw-  2.0 fat     5376 b- defN 23-Mar-29 08:36 cumm/gemm/dev/__init__.py
--rw-rw-rw-  2.0 fat    47699 b- defN 23-Mar-29 08:36 cumm/gemm/frozen/__init__.py
--rw-rw-rw-  2.0 fat    47699 b- defN 23-Mar-29 08:36 cumm/gemm/frozen/mask_iters.py
--rw-rw-rw-  2.0 fat     7988 b- defN 23-Mar-29 08:36 cumm/gemm/gemmmath/__init__.py
--rw-rw-rw-  2.0 fat      615 b- defN 23-Mar-29 08:36 cumm/gemm/output_op/__init__.py
--rw-rw-rw-  2.0 fat    10017 b- defN 23-Mar-29 08:36 cumm/gemm/output_op/apply.py
--rw-rw-rw-  2.0 fat    16722 b- defN 23-Mar-29 08:36 cumm/gemm/output_op/linear.py
--rw-rw-rw-  2.0 fat    19506 b- defN 23-Mar-29 08:36 cumm/gemm/outputs/__init__.py
--rw-rw-rw-  2.0 fat      621 b- defN 23-Mar-29 08:36 cumm/gemm/wmma/__init__.py
--rw-rw-rw-  2.0 fat    21856 b- defN 23-Mar-29 08:36 cumm/gemm/wmma/simt.py
--rw-rw-rw-  2.0 fat     7428 b- defN 23-Mar-29 08:36 cumm/gemm/wmma/turing.py
--rw-rw-rw-  2.0 fat     7711 b- defN 23-Mar-29 08:36 cumm/gemm/wmma/volta.py
--rw-rw-rw-  2.0 fat      589 b- defN 23-Mar-29 08:36 cumm/gemmv2/__init__.py
--rw-rw-rw-  2.0 fat       36 b- defN 23-Mar-29 08:36 cumm/include/tensorview/cc17.h
--rw-rw-rw-  2.0 fat     2175 b- defN 23-Mar-29 08:36 cumm/include/tensorview/check.h
--rw-rw-rw-  2.0 fat       40 b- defN 23-Mar-29 08:36 cumm/include/tensorview/common.h
--rw-rw-rw-  2.0 fat       40 b- defN 23-Mar-29 08:36 cumm/include/tensorview/context.h
--rw-rw-rw-  2.0 fat       38 b- defN 23-Mar-29 08:36 cumm/include/tensorview/cuda_utils.h
--rw-rw-rw-  2.0 fat       43 b- defN 23-Mar-29 08:36 cumm/include/tensorview/device_ops.h
--rw-rw-rw-  2.0 fat    12293 b- defN 23-Mar-29 08:36 cumm/include/tensorview/dtypes.h
--rw-rw-rw-  2.0 fat       56 b- defN 23-Mar-29 08:36 cumm/include/tensorview/kernel_utils.h
--rw-rw-rw-  2.0 fat       53 b- defN 23-Mar-29 08:36 cumm/include/tensorview/mp_helper.h
--rw-rw-rw-  2.0 fat    16874 b- defN 23-Mar-29 08:36 cumm/include/tensorview/prettyprint.h
--rw-rw-rw-  2.0 fat     9916 b- defN 23-Mar-29 08:36 cumm/include/tensorview/pybind.h
--rw-rw-rw-  2.0 fat       33 b- defN 23-Mar-29 08:36 cumm/include/tensorview/pybind_utils.h
--rw-rw-rw-  2.0 fat     3632 b- defN 23-Mar-29 08:36 cumm/include/tensorview/simple_ops.h
--rw-rw-rw-  2.0 fat    63147 b- defN 23-Mar-29 08:36 cumm/include/tensorview/tensor.h
--rw-rw-rw-  2.0 fat    38575 b- defN 23-Mar-29 08:36 cumm/include/tensorview/tensorview.h
--rw-rw-rw-  2.0 fat     2163 b- defN 23-Mar-29 08:36 cumm/include/tensorview/tools.h
--rw-rw-rw-  2.0 fat     8239 b- defN 23-Mar-29 08:36 cumm/include/tensorview/torch_utils.h
--rw-rw-rw-  2.0 fat     4884 b- defN 23-Mar-29 08:36 cumm/include/tensorview/contexts/core.h
--rw-rw-rw-  2.0 fat     2044 b- defN 23-Mar-29 08:36 cumm/include/tensorview/contexts/cuda_blas.h
--rw-rw-rw-  2.0 fat      802 b- defN 23-Mar-29 08:36 cumm/include/tensorview/core/all.h
--rw-rw-rw-  2.0 fat    27833 b- defN 23-Mar-29 08:36 cumm/include/tensorview/core/array.h
--rw-rw-rw-  2.0 fat    15394 b- defN 23-Mar-29 08:36 cumm/include/tensorview/core/cc17.h
--rw-rw-rw-  2.0 fat    13082 b- defN 23-Mar-29 08:36 cumm/include/tensorview/core/common.h
--rw-rw-rw-  2.0 fat      884 b- defN 23-Mar-29 08:36 cumm/include/tensorview/core/const_ops.h
--rw-rw-rw-  2.0 fat     3925 b- defN 23-Mar-29 08:36 cumm/include/tensorview/core/const_string.h
--rw-rw-rw-  2.0 fat     2872 b- defN 23-Mar-29 08:36 cumm/include/tensorview/core/defs.h
--rw-rw-rw-  2.0 fat    24509 b- defN 23-Mar-29 08:36 cumm/include/tensorview/core/mp_helper.h
--rw-rw-rw-  2.0 fat     1186 b- defN 23-Mar-29 08:36 cumm/include/tensorview/core/nvrtc_std.h
--rw-rw-rw-  2.0 fat     8260 b- defN 23-Mar-29 08:36 cumm/include/tensorview/core/printf2.h
--rw-rw-rw-  2.0 fat     6514 b- defN 23-Mar-29 08:36 cumm/include/tensorview/core/vecarray.h
--rw-rw-rw-  2.0 fat       59 b- defN 23-Mar-29 08:36 cumm/include/tensorview/core/arrayops/all.h
--rw-rw-rw-  2.0 fat    34508 b- defN 23-Mar-29 08:36 cumm/include/tensorview/core/arrayops/linalg.h
--rw-rw-rw-  2.0 fat    23355 b- defN 23-Mar-29 08:36 cumm/include/tensorview/core/arrayops/mathbase.h
--rw-rw-rw-  2.0 fat     5579 b- defN 23-Mar-29 08:36 cumm/include/tensorview/core/arrayops/simple.h
--rw-rw-rw-  2.0 fat     1951 b- defN 23-Mar-29 08:36 cumm/include/tensorview/core/nvrtc/core.h
--rw-rw-rw-  2.0 fat    38943 b- defN 23-Mar-29 08:36 cumm/include/tensorview/core/nvrtc/limits.h
--rw-rw-rw-  2.0 fat       85 b- defN 23-Mar-29 08:36 cumm/include/tensorview/core/nvrtc/runtime_include.h
--rw-rw-rw-  2.0 fat     3126 b- defN 23-Mar-29 08:36 cumm/include/tensorview/core/nvrtc/tuple.h
--rw-rw-rw-  2.0 fat    14509 b- defN 23-Mar-29 08:36 cumm/include/tensorview/core/nvrtc/type_traits.h
--rw-rw-rw-  2.0 fat      661 b- defN 23-Mar-29 08:36 cumm/include/tensorview/cuda/all.h
--rw-rw-rw-  2.0 fat     1008 b- defN 23-Mar-29 08:36 cumm/include/tensorview/cuda/arch_defs.h
--rw-rw-rw-  2.0 fat     2954 b- defN 23-Mar-29 08:36 cumm/include/tensorview/cuda/device_ops.h
--rw-rw-rw-  2.0 fat     9497 b- defN 23-Mar-29 08:36 cumm/include/tensorview/cuda/driver.h
--rw-rw-rw-  2.0 fat    16164 b- defN 23-Mar-29 08:36 cumm/include/tensorview/cuda/driverops.h
--rw-rw-rw-  2.0 fat      685 b- defN 23-Mar-29 08:36 cumm/include/tensorview/cuda/kernel_all.h
--rw-rw-rw-  2.0 fat     3917 b- defN 23-Mar-29 08:36 cumm/include/tensorview/cuda/kernel_utils.h
--rw-rw-rw-  2.0 fat     3612 b- defN 23-Mar-29 08:36 cumm/include/tensorview/cuda/launch.h
--rw-rw-rw-  2.0 fat    19539 b- defN 23-Mar-29 08:36 cumm/include/tensorview/cuda/nvrtc.h
--rw-rw-rw-  2.0 fat      873 b- defN 23-Mar-29 08:36 cumm/include/tensorview/gemm/constants.h
--rw-rw-rw-  2.0 fat     1019 b- defN 23-Mar-29 08:36 cumm/include/tensorview/gemm/cutlass_compat.h
--rw-rw-rw-  2.0 fat     5823 b- defN 23-Mar-29 08:36 cumm/include/tensorview/gemm/debug.h
--rw-rw-rw-  2.0 fat    10006 b- defN 23-Mar-29 08:36 cumm/include/tensorview/gemm/arch/memory.h
--rw-rw-rw-  2.0 fat     4899 b- defN 23-Mar-29 08:36 cumm/include/tensorview/gemm/arch/memory_sm75.h
--rw-rw-rw-  2.0 fat     4023 b- defN 23-Mar-29 08:36 cumm/include/tensorview/gemm/arch/semaphore.h
--rw-rw-rw-  2.0 fat     4967 b- defN 23-Mar-29 08:36 cumm/include/tensorview/gemm/arch/transpose.h
--rw-rw-rw-  2.0 fat     1505 b- defN 23-Mar-29 08:36 cumm/include/tensorview/gemm/core/constants.h
--rw-rw-rw-  2.0 fat     1074 b- defN 23-Mar-29 08:36 cumm/include/tensorview/gemm/core/nvrtc_bases.h
--rw-rw-rw-  2.0 fat     2164 b- defN 23-Mar-29 08:36 cumm/include/tensorview/gemm/core/nvrtc_params.h
--rw-rw-rw-  2.0 fat    14835 b- defN 23-Mar-29 08:36 cumm/include/tensorview/gemm/core/params.h
--rw-rw-rw-  2.0 fat     4051 b- defN 23-Mar-29 08:36 cumm/include/tensorview/gemm/core/utils.h
--rw-rw-rw-  2.0 fat      815 b- defN 23-Mar-29 08:36 cumm/include/tensorview/gemm/dtypes/all.h
--rw-rw-rw-  2.0 fat    13773 b- defN 23-Mar-29 08:36 cumm/include/tensorview/gemm/dtypes/bfloat16.h
--rw-rw-rw-  2.0 fat      647 b- defN 23-Mar-29 08:36 cumm/include/tensorview/gemm/dtypes/common.h
--rw-rw-rw-  2.0 fat    14986 b- defN 23-Mar-29 08:36 cumm/include/tensorview/gemm/dtypes/complex.h
--rw-rw-rw-  2.0 fat    34614 b- defN 23-Mar-29 08:36 cumm/include/tensorview/gemm/dtypes/float8.h
--rw-rw-rw-  2.0 fat      935 b- defN 23-Mar-29 08:36 cumm/include/tensorview/gemm/dtypes/fp_nvrtc.h
--rw-rw-rw-  2.0 fat    21572 b- defN 23-Mar-29 08:36 cumm/include/tensorview/gemm/dtypes/half.h
--rw-rw-rw-  2.0 fat     6042 b- defN 23-Mar-29 08:36 cumm/include/tensorview/gemm/dtypes/subint.h
--rw-rw-rw-  2.0 fat    13276 b- defN 23-Mar-29 08:36 cumm/include/tensorview/gemm/dtypes/tf32.h
--rw-rw-rw-  2.0 fat     7706 b- defN 23-Mar-29 08:36 cumm/include/tensorview/gemm/dtypes/uint128.h
--rw-rw-rw-  2.0 fat     1749 b- defN 23-Mar-29 08:36 cumm/include/tensorview/gemm/math/activation.h
--rw-rw-rw-  2.0 fat      725 b- defN 23-Mar-29 08:36 cumm/include/tensorview/gemm/math/all.h
--rw-rw-rw-  2.0 fat    45005 b- defN 23-Mar-29 08:36 cumm/include/tensorview/gemm/math/functional.h
--rw-rw-rw-  2.0 fat    75746 b- defN 23-Mar-29 08:36 cumm/include/tensorview/gemm/math/numeric_convert.h
--rw-rw-rw-  2.0 fat      707 b- defN 23-Mar-29 08:36 cumm/include/tensorview/hash/all.cu.h
--rw-rw-rw-  2.0 fat      597 b- defN 23-Mar-29 08:36 cumm/include/tensorview/hash/all.h
--rw-rw-rw-  2.0 fat     2512 b- defN 23-Mar-29 08:36 cumm/include/tensorview/hash/dense.cu.h
--rw-rw-rw-  2.0 fat     8727 b- defN 23-Mar-29 08:36 cumm/include/tensorview/hash/hash.cu.h
--rw-rw-rw-  2.0 fat     3382 b- defN 23-Mar-29 08:36 cumm/include/tensorview/hash/hash_core.h
--rw-rw-rw-  2.0 fat     8559 b- defN 23-Mar-29 08:36 cumm/include/tensorview/hash/hash_functions.h
--rw-rw-rw-  2.0 fat    16464 b- defN 23-Mar-29 08:36 cumm/include/tensorview/hash/linear.cu.h
--rw-rw-rw-  2.0 fat      739 b- defN 23-Mar-29 08:36 cumm/include/tensorview/hash/multilinear.cu.h
--rw-rw-rw-  2.0 fat     6056 b- defN 23-Mar-29 08:36 cumm/include/tensorview/hash/ops.h
--rw-rw-rw-  2.0 fat     8754 b- defN 23-Mar-29 08:36 cumm/include/tensorview/io/jsonarray.h
--rw-rw-rw-  2.0 fat      679 b- defN 23-Mar-29 08:36 cumm/include/tensorview/math/all.h
--rw-rw-rw-  2.0 fat     1020 b- defN 23-Mar-29 08:36 cumm/include/tensorview/math/array_ops.h
--rw-rw-rw-  2.0 fat    17043 b- defN 23-Mar-29 08:36 cumm/include/tensorview/math/fastmath.h
--rw-rw-rw-  2.0 fat      943 b- defN 23-Mar-29 08:36 cumm/include/tensorview/math/scalar.h
--rw-rw-rw-  2.0 fat      652 b- defN 23-Mar-29 08:36 cumm/include/tensorview/parallel/all.h
--rw-rw-rw-  2.0 fat    12654 b- defN 23-Mar-29 08:36 cumm/include/tensorview/parallel/kernel1d.h
--rw-rw-rw-  2.0 fat     2821 b- defN 23-Mar-29 08:36 cumm/include/tensorview/parallel/map.h
--rw-rw-rw-  2.0 fat     1422 b- defN 23-Mar-29 08:36 cumm/include/tensorview/parallel/ops.h
--rw-rw-rw-  2.0 fat      625 b- defN 23-Mar-29 08:36 cumm/include/tensorview/profile/all.h
--rw-rw-rw-  2.0 fat    12145 b- defN 23-Mar-29 08:36 cumm/include/tensorview/profile/cuda_profiler.h
--rw-rw-rw-  2.0 fat   932454 b- defN 23-Mar-29 08:36 cumm/include/tensorview/thirdparty/nlohmann/json.hpp
--rw-rw-rw-  2.0 fat    12179 b- defN 23-Mar-29 08:36 cumm/include/tensorview/thirdparty/tsl/robin_growth_policy.h
--rw-rw-rw-  2.0 fat    55430 b- defN 23-Mar-29 08:36 cumm/include/tensorview/thirdparty/tsl/robin_hash.h
--rw-rw-rw-  2.0 fat    29219 b- defN 23-Mar-29 08:36 cumm/include/tensorview/thirdparty/tsl/robin_map.h
--rw-rw-rw-  2.0 fat    24253 b- defN 23-Mar-29 08:36 cumm/include/tensorview/thirdparty/tsl/robin_set.h
--rw-rw-rw-  2.0 fat     1416 b- defN 23-Mar-29 08:36 cumm/include/tensorview/utility/tuplehash.h
--rw-rw-rw-  2.0 fat    17061 b- defN 23-Mar-29 08:36 cumm/inliner/__init__.py
--rw-rw-rw-  2.0 fat    20101 b- defN 23-Mar-29 08:36 cumm/nvrtc/__init__.py
--rw-rw-rw-  2.0 fat     1240 b- defN 23-Mar-29 08:36 cumm/nvrtc/dev.py
--rw-rw-rw-  2.0 fat      589 b- defN 23-Mar-29 08:36 cumm/services/__init__.py
--rw-rw-rw-  2.0 fat     1041 b- defN 23-Mar-29 08:36 cumm/services/nvrtc.py
--rw-rw-rw-  2.0 fat    21260 b- defN 23-Mar-29 08:36 cumm/tensorview/__init__.py
--rw-rw-rw-  2.0 fat     2657 b- defN 23-Mar-29 08:36 cumm/tensorview/creator.py
--rw-rw-rw-  2.0 fat     1038 b- defN 23-Mar-29 08:36 cumm/tensorview/gemm.py
--rw-rw-rw-  2.0 fat     9460 b- defN 23-Mar-29 08:36 cumm/tensorview/tvio.py
--rw-rw-rw-  2.0 fat      134 b- defN 23-Mar-29 08:36 cumm/tensorview/utils.py
--rw-rw-rw-  2.0 fat    11536 b- defN 23-Mar-29 08:56 cumm_cu120-0.4.8.dist-info/LICENSE
--rw-rw-rw-  2.0 fat     6392 b- defN 23-Mar-29 08:56 cumm_cu120-0.4.8.dist-info/METADATA
--rw-rw-rw-  2.0 fat      100 b- defN 23-Mar-29 08:56 cumm_cu120-0.4.8.dist-info/WHEEL
--rw-rw-rw-  2.0 fat       13 b- defN 23-Mar-29 08:55 cumm_cu120-0.4.8.dist-info/top_level.txt
--rw-rw-r--  2.0 fat    19293 b- defN 23-Mar-29 08:56 cumm_cu120-0.4.8.dist-info/RECORD
-217 files, 4890933 bytes uncompressed, 1070711 bytes compressed:  78.1%
+Zip file size: 1108638 bytes, number of entries: 217
+-rw-rw-rw-  2.0 fat     1340 b- defN 23-Apr-26 09:47 cumm/__init__.py
+-rw-rw-rw-  2.0 fat       23 b- defN 23-Apr-26 10:10 cumm/__version__.py
+-rw-rw-rw-  2.0 fat    29533 b- defN 23-Apr-26 09:47 cumm/common.py
+-rw-rw-rw-  2.0 fat     1764 b- defN 23-Apr-26 09:47 cumm/constants.py
+-rw-rw-rw-  2.0 fat  1059328 b- defN 23-Apr-26 10:12 cumm/core_cc.cp39-win_amd64.pyd
+-rw-rw-rw-  2.0 fat     5888 b- defN 23-Apr-26 09:47 cumm/dtypes.py
+-rw-rw-rw-  2.0 fat     6575 b- defN 23-Apr-26 09:47 cumm/inliner.py
+-rw-rw-rw-  2.0 fat    41098 b- defN 23-Apr-26 09:47 cumm/tensorview_bind.py
+-rw-rw-rw-  2.0 fat    18474 b- defN 23-Apr-26 09:47 cumm/tensorview_bind_anno.pyi
+-rw-rw-rw-  2.0 fat      589 b- defN 23-Apr-26 09:47 cumm/cmds/__init__.py
+-rw-rw-rw-  2.0 fat      589 b- defN 23-Apr-26 09:47 cumm/cmds/include_path/__init__.py
+-rw-rw-rw-  2.0 fat      121 b- defN 23-Apr-26 09:47 cumm/cmds/include_path/__main__.py
+-rw-rw-rw-  2.0 fat      584 b- defN 23-Apr-26 09:47 cumm/conv/__init__.py
+-rw-rw-rw-  2.0 fat     3125 b- defN 23-Apr-26 09:47 cumm/conv/algo.py
+-rw-rw-rw-  2.0 fat     3634 b- defN 23-Apr-26 09:47 cumm/conv/bases.py
+-rw-rw-rw-  2.0 fat   123453 b- defN 23-Apr-26 09:47 cumm/conv/input_iters.py
+-rw-rw-rw-  2.0 fat    63083 b- defN 23-Apr-26 09:47 cumm/conv/kernel.py
+-rw-rw-rw-  2.0 fat    68276 b- defN 23-Apr-26 09:47 cumm/conv/main.py
+-rw-rw-rw-  2.0 fat    22169 b- defN 23-Apr-26 09:47 cumm/conv/main_real.py
+-rw-rw-rw-  2.0 fat    19016 b- defN 23-Apr-26 09:47 cumm/conv/main_real_spconv.py
+-rw-rw-rw-  2.0 fat    17968 b- defN 23-Apr-26 09:47 cumm/conv/nvrtc_code.py
+-rw-rw-rw-  2.0 fat    18947 b- defN 23-Apr-26 09:47 cumm/conv/params.py
+-rw-rw-rw-  2.0 fat    50736 b- defN 23-Apr-26 09:47 cumm/conv/sparse_iters.py
+-rw-rw-rw-  2.0 fat      690 b- defN 23-Apr-26 09:47 cumm/conv/algospec/__init__.py
+-rw-rw-rw-  2.0 fat     1263 b- defN 23-Apr-26 09:47 cumm/conv/algospec/all.py
+-rw-rw-rw-  2.0 fat      734 b- defN 23-Apr-26 09:47 cumm/conv/algospec/core.py
+-rw-rw-rw-  2.0 fat    10008 b- defN 23-Apr-26 09:47 cumm/conv/algospec/simt.py
+-rw-rw-rw-  2.0 fat    12175 b- defN 23-Apr-26 09:47 cumm/conv/algospec/turing.py
+-rw-rw-rw-  2.0 fat    10372 b- defN 23-Apr-26 09:47 cumm/conv/algospec/volta.py
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Apr-26 10:10 cumm/core_cc/__init__.pyi
+-rw-rw-rw-  2.0 fat    18687 b- defN 23-Apr-26 10:10 cumm/core_cc/tensorview_bind.pyi
+-rw-rw-rw-  2.0 fat        0 b- defN 23-Apr-26 10:10 cumm/core_cc/csrc/__init__.pyi
+-rw-rw-rw-  2.0 fat     2888 b- defN 23-Apr-26 10:10 cumm/core_cc/csrc/arrayref.pyi
+-rw-rw-rw-  2.0 fat      584 b- defN 23-Apr-26 09:47 cumm/csrc/__init__.py
+-rw-rw-rw-  2.0 fat    17946 b- defN 23-Apr-26 09:47 cumm/csrc/arrayref.py
+-rw-rw-rw-  2.0 fat     8173 b- defN 23-Apr-26 09:47 cumm/cudasim/__init__.py
+-rw-rw-rw-  2.0 fat     1668 b- defN 23-Apr-26 09:47 cumm/cudasim/checkers.py
+-rw-rw-rw-  2.0 fat     1679 b- defN 23-Apr-26 09:47 cumm/cudasim/debug.py
+-rw-rw-rw-  2.0 fat      589 b- defN 23-Apr-26 09:47 cumm/devapps/__init__.py
+-rw-rw-rw-  2.0 fat     2925 b- defN 23-Apr-26 09:47 cumm/devapps/template.py
+-rw-rw-rw-  2.0 fat      589 b- defN 23-Apr-26 09:47 cumm/develop/__init__.py
+-rw-rw-rw-  2.0 fat     3149 b- defN 23-Apr-26 09:47 cumm/develop/eigendev.py
+-rw-rw-rw-  2.0 fat     6945 b- defN 23-Apr-26 09:47 cumm/develop/mathgen.py
+-rw-rw-rw-  2.0 fat      613 b- defN 23-Apr-26 09:47 cumm/gemm/__init__.py
+-rw-rw-rw-  2.0 fat    10838 b- defN 23-Apr-26 09:47 cumm/gemm/bases.py
+-rw-rw-rw-  2.0 fat     3116 b- defN 23-Apr-26 09:47 cumm/gemm/codeops.py
+-rw-rw-rw-  2.0 fat     2082 b- defN 23-Apr-26 09:47 cumm/gemm/constants.py
+-rw-rw-rw-  2.0 fat    13157 b- defN 23-Apr-26 09:47 cumm/gemm/cutlasstest.py
+-rw-rw-rw-  2.0 fat     3121 b- defN 23-Apr-26 09:47 cumm/gemm/dev_gemm.py
+-rw-rw-rw-  2.0 fat    25132 b- defN 23-Apr-26 09:47 cumm/gemm/gather.py
+-rw-rw-rw-  2.0 fat    54527 b- defN 23-Apr-26 09:47 cumm/gemm/kernel.py
+-rw-rw-rw-  2.0 fat    26748 b- defN 23-Apr-26 09:47 cumm/gemm/layout.py
+-rw-rw-rw-  2.0 fat    30873 b- defN 23-Apr-26 09:47 cumm/gemm/layout_tensorop.py
+-rw-rw-rw-  2.0 fat    87853 b- defN 23-Apr-26 09:47 cumm/gemm/main.py
+-rw-rw-rw-  2.0 fat     3722 b- defN 23-Apr-26 09:47 cumm/gemm/main_profile.py
+-rw-rw-rw-  2.0 fat    34988 b- defN 23-Apr-26 09:47 cumm/gemm/main_real.py
+-rw-rw-rw-  2.0 fat    11527 b- defN 23-Apr-26 09:47 cumm/gemm/main_real_test.py
+-rw-rw-rw-  2.0 fat    33776 b- defN 23-Apr-26 09:47 cumm/gemm/main_simu.py
+-rw-rw-rw-  2.0 fat     7417 b- defN 23-Apr-26 09:47 cumm/gemm/mask.py
+-rw-rw-rw-  2.0 fat    74834 b- defN 23-Apr-26 09:47 cumm/gemm/mask_iters.py
+-rw-rw-rw-  2.0 fat    13730 b- defN 23-Apr-26 09:47 cumm/gemm/nvrtc_code.py
+-rw-rw-rw-  2.0 fat    44487 b- defN 23-Apr-26 09:47 cumm/gemm/out_iters.py
+-rw-rw-rw-  2.0 fat      584 b- defN 23-Apr-26 09:47 cumm/gemm/output.py
+-rw-rw-rw-  2.0 fat    23481 b- defN 23-Apr-26 09:47 cumm/gemm/thread_map.py
+-rw-rw-rw-  2.0 fat    76058 b- defN 23-Apr-26 09:47 cumm/gemm/turing_iters.py
+-rw-rw-rw-  2.0 fat    85772 b- defN 23-Apr-26 09:47 cumm/gemm/turing_my_iters.py
+-rw-rw-rw-  2.0 fat    39273 b- defN 23-Apr-26 09:47 cumm/gemm/turing_out_iters.py
+-rw-rw-rw-  2.0 fat     3704 b- defN 23-Apr-26 09:47 cumm/gemm/utils.py
+-rw-rw-rw-  2.0 fat    40533 b- defN 23-Apr-26 09:47 cumm/gemm/volta_iters.py
+-rw-rw-rw-  2.0 fat    20364 b- defN 23-Apr-26 09:47 cumm/gemm/volta_out_iters.py
+-rw-rw-rw-  2.0 fat      802 b- defN 23-Apr-26 09:47 cumm/gemm/algospec/__init__.py
+-rw-rw-rw-  2.0 fat     1303 b- defN 23-Apr-26 09:47 cumm/gemm/algospec/all.py
+-rw-rw-rw-  2.0 fat     5349 b- defN 23-Apr-26 09:47 cumm/gemm/algospec/bases.py
+-rw-rw-rw-  2.0 fat     3408 b- defN 23-Apr-26 09:47 cumm/gemm/algospec/core.py
+-rw-rw-rw-  2.0 fat    20980 b- defN 23-Apr-26 09:47 cumm/gemm/algospec/simt.py
+-rw-rw-rw-  2.0 fat    24737 b- defN 23-Apr-26 09:47 cumm/gemm/algospec/turing.py
+-rw-rw-rw-  2.0 fat    17206 b- defN 23-Apr-26 09:47 cumm/gemm/algospec/volta.py
+-rw-rw-rw-  2.0 fat      610 b- defN 23-Apr-26 09:47 cumm/gemm/arch/__init__.py
+-rw-rw-rw-  2.0 fat    10848 b- defN 23-Apr-26 09:47 cumm/gemm/arch/cpasync.py
+-rw-rw-rw-  2.0 fat     9819 b- defN 23-Apr-26 09:47 cumm/gemm/arch/instmma.py
+-rw-rw-rw-  2.0 fat     4438 b- defN 23-Apr-26 09:47 cumm/gemm/arch/ldmatrix.py
+-rw-rw-rw-  2.0 fat     4201 b- defN 23-Apr-26 09:47 cumm/gemm/arch/memory.py
+-rw-rw-rw-  2.0 fat    32651 b- defN 23-Apr-26 09:47 cumm/gemm/arch/tensorop.py
+-rw-rw-rw-  2.0 fat      693 b- defN 23-Apr-26 09:47 cumm/gemm/blockmma/__init__.py
+-rw-rw-rw-  2.0 fat    61187 b- defN 23-Apr-26 09:47 cumm/gemm/blockmma/mma.py
+-rw-rw-rw-  2.0 fat     4737 b- defN 23-Apr-26 09:47 cumm/gemm/blockmma/mma_async.py
+-rw-rw-rw-  2.0 fat    58734 b- defN 23-Apr-26 09:47 cumm/gemm/blockmma/mma_multistage.py
+-rw-rw-rw-  2.0 fat     1207 b- defN 23-Apr-26 09:47 cumm/gemm/core/__init__.py
+-rw-rw-rw-  2.0 fat     4194 b- defN 23-Apr-26 09:47 cumm/gemm/core/metaarray.py
+-rw-rw-rw-  2.0 fat     5376 b- defN 23-Apr-26 09:47 cumm/gemm/dev/__init__.py
+-rw-rw-rw-  2.0 fat    47699 b- defN 23-Apr-26 09:47 cumm/gemm/frozen/__init__.py
+-rw-rw-rw-  2.0 fat    47699 b- defN 23-Apr-26 09:47 cumm/gemm/frozen/mask_iters.py
+-rw-rw-rw-  2.0 fat     7988 b- defN 23-Apr-26 09:47 cumm/gemm/gemmmath/__init__.py
+-rw-rw-rw-  2.0 fat      615 b- defN 23-Apr-26 09:47 cumm/gemm/output_op/__init__.py
+-rw-rw-rw-  2.0 fat    10017 b- defN 23-Apr-26 09:47 cumm/gemm/output_op/apply.py
+-rw-rw-rw-  2.0 fat    16722 b- defN 23-Apr-26 09:47 cumm/gemm/output_op/linear.py
+-rw-rw-rw-  2.0 fat    19506 b- defN 23-Apr-26 09:47 cumm/gemm/outputs/__init__.py
+-rw-rw-rw-  2.0 fat      621 b- defN 23-Apr-26 09:47 cumm/gemm/wmma/__init__.py
+-rw-rw-rw-  2.0 fat    21856 b- defN 23-Apr-26 09:47 cumm/gemm/wmma/simt.py
+-rw-rw-rw-  2.0 fat     7428 b- defN 23-Apr-26 09:47 cumm/gemm/wmma/turing.py
+-rw-rw-rw-  2.0 fat     7711 b- defN 23-Apr-26 09:47 cumm/gemm/wmma/volta.py
+-rw-rw-rw-  2.0 fat      589 b- defN 23-Apr-26 09:47 cumm/gemmv2/__init__.py
+-rw-rw-rw-  2.0 fat       36 b- defN 23-Apr-26 09:47 cumm/include/tensorview/cc17.h
+-rw-rw-rw-  2.0 fat     2187 b- defN 23-Apr-26 09:47 cumm/include/tensorview/check.h
+-rw-rw-rw-  2.0 fat       40 b- defN 23-Apr-26 09:47 cumm/include/tensorview/common.h
+-rw-rw-rw-  2.0 fat       40 b- defN 23-Apr-26 09:47 cumm/include/tensorview/context.h
+-rw-rw-rw-  2.0 fat       38 b- defN 23-Apr-26 09:47 cumm/include/tensorview/cuda_utils.h
+-rw-rw-rw-  2.0 fat       43 b- defN 23-Apr-26 09:47 cumm/include/tensorview/device_ops.h
+-rw-rw-rw-  2.0 fat    12293 b- defN 23-Apr-26 09:47 cumm/include/tensorview/dtypes.h
+-rw-rw-rw-  2.0 fat       56 b- defN 23-Apr-26 09:47 cumm/include/tensorview/kernel_utils.h
+-rw-rw-rw-  2.0 fat       53 b- defN 23-Apr-26 09:47 cumm/include/tensorview/mp_helper.h
+-rw-rw-rw-  2.0 fat    16874 b- defN 23-Apr-26 09:47 cumm/include/tensorview/prettyprint.h
+-rw-rw-rw-  2.0 fat     9916 b- defN 23-Apr-26 09:47 cumm/include/tensorview/pybind.h
+-rw-rw-rw-  2.0 fat       33 b- defN 23-Apr-26 09:47 cumm/include/tensorview/pybind_utils.h
+-rw-rw-rw-  2.0 fat     3632 b- defN 23-Apr-26 09:47 cumm/include/tensorview/simple_ops.h
+-rw-rw-rw-  2.0 fat    63520 b- defN 23-Apr-26 09:47 cumm/include/tensorview/tensor.h
+-rw-rw-rw-  2.0 fat    38851 b- defN 23-Apr-26 09:47 cumm/include/tensorview/tensorview.h
+-rw-rw-rw-  2.0 fat     2163 b- defN 23-Apr-26 09:47 cumm/include/tensorview/tools.h
+-rw-rw-rw-  2.0 fat     8239 b- defN 23-Apr-26 09:47 cumm/include/tensorview/torch_utils.h
+-rw-rw-rw-  2.0 fat     4884 b- defN 23-Apr-26 09:47 cumm/include/tensorview/contexts/core.h
+-rw-rw-rw-  2.0 fat     2044 b- defN 23-Apr-26 09:47 cumm/include/tensorview/contexts/cuda_blas.h
+-rw-rw-rw-  2.0 fat      802 b- defN 23-Apr-26 09:47 cumm/include/tensorview/core/all.h
+-rw-rw-rw-  2.0 fat    27833 b- defN 23-Apr-26 09:47 cumm/include/tensorview/core/array.h
+-rw-rw-rw-  2.0 fat    15394 b- defN 23-Apr-26 09:47 cumm/include/tensorview/core/cc17.h
+-rw-rw-rw-  2.0 fat    13287 b- defN 23-Apr-26 09:47 cumm/include/tensorview/core/common.h
+-rw-rw-rw-  2.0 fat      884 b- defN 23-Apr-26 09:47 cumm/include/tensorview/core/const_ops.h
+-rw-rw-rw-  2.0 fat     3925 b- defN 23-Apr-26 09:47 cumm/include/tensorview/core/const_string.h
+-rw-rw-rw-  2.0 fat     2872 b- defN 23-Apr-26 09:47 cumm/include/tensorview/core/defs.h
+-rw-rw-rw-  2.0 fat    24509 b- defN 23-Apr-26 09:47 cumm/include/tensorview/core/mp_helper.h
+-rw-rw-rw-  2.0 fat     1186 b- defN 23-Apr-26 09:47 cumm/include/tensorview/core/nvrtc_std.h
+-rw-rw-rw-  2.0 fat     8260 b- defN 23-Apr-26 09:47 cumm/include/tensorview/core/printf2.h
+-rw-rw-rw-  2.0 fat     6514 b- defN 23-Apr-26 09:47 cumm/include/tensorview/core/vecarray.h
+-rw-rw-rw-  2.0 fat       59 b- defN 23-Apr-26 09:47 cumm/include/tensorview/core/arrayops/all.h
+-rw-rw-rw-  2.0 fat    34508 b- defN 23-Apr-26 09:47 cumm/include/tensorview/core/arrayops/linalg.h
+-rw-rw-rw-  2.0 fat    23355 b- defN 23-Apr-26 09:47 cumm/include/tensorview/core/arrayops/mathbase.h
+-rw-rw-rw-  2.0 fat     5579 b- defN 23-Apr-26 09:47 cumm/include/tensorview/core/arrayops/simple.h
+-rw-rw-rw-  2.0 fat     1951 b- defN 23-Apr-26 09:47 cumm/include/tensorview/core/nvrtc/core.h
+-rw-rw-rw-  2.0 fat    38943 b- defN 23-Apr-26 09:47 cumm/include/tensorview/core/nvrtc/limits.h
+-rw-rw-rw-  2.0 fat       85 b- defN 23-Apr-26 09:47 cumm/include/tensorview/core/nvrtc/runtime_include.h
+-rw-rw-rw-  2.0 fat     3126 b- defN 23-Apr-26 09:47 cumm/include/tensorview/core/nvrtc/tuple.h
+-rw-rw-rw-  2.0 fat    15490 b- defN 23-Apr-26 09:47 cumm/include/tensorview/core/nvrtc/type_traits.h
+-rw-rw-rw-  2.0 fat      661 b- defN 23-Apr-26 09:47 cumm/include/tensorview/cuda/all.h
+-rw-rw-rw-  2.0 fat     1008 b- defN 23-Apr-26 09:47 cumm/include/tensorview/cuda/arch_defs.h
+-rw-rw-rw-  2.0 fat     2954 b- defN 23-Apr-26 09:47 cumm/include/tensorview/cuda/device_ops.h
+-rw-rw-rw-  2.0 fat     9497 b- defN 23-Apr-26 09:47 cumm/include/tensorview/cuda/driver.h
+-rw-rw-rw-  2.0 fat    16164 b- defN 23-Apr-26 09:47 cumm/include/tensorview/cuda/driverops.h
+-rw-rw-rw-  2.0 fat      685 b- defN 23-Apr-26 09:47 cumm/include/tensorview/cuda/kernel_all.h
+-rw-rw-rw-  2.0 fat     3917 b- defN 23-Apr-26 09:47 cumm/include/tensorview/cuda/kernel_utils.h
+-rw-rw-rw-  2.0 fat     3612 b- defN 23-Apr-26 09:47 cumm/include/tensorview/cuda/launch.h
+-rw-rw-rw-  2.0 fat    20406 b- defN 23-Apr-26 09:47 cumm/include/tensorview/cuda/nvrtc.h
+-rw-rw-rw-  2.0 fat      873 b- defN 23-Apr-26 09:47 cumm/include/tensorview/gemm/constants.h
+-rw-rw-rw-  2.0 fat     1019 b- defN 23-Apr-26 09:47 cumm/include/tensorview/gemm/cutlass_compat.h
+-rw-rw-rw-  2.0 fat     5823 b- defN 23-Apr-26 09:47 cumm/include/tensorview/gemm/debug.h
+-rw-rw-rw-  2.0 fat    10006 b- defN 23-Apr-26 09:47 cumm/include/tensorview/gemm/arch/memory.h
+-rw-rw-rw-  2.0 fat     4899 b- defN 23-Apr-26 09:47 cumm/include/tensorview/gemm/arch/memory_sm75.h
+-rw-rw-rw-  2.0 fat     4023 b- defN 23-Apr-26 09:47 cumm/include/tensorview/gemm/arch/semaphore.h
+-rw-rw-rw-  2.0 fat     4967 b- defN 23-Apr-26 09:47 cumm/include/tensorview/gemm/arch/transpose.h
+-rw-rw-rw-  2.0 fat     1505 b- defN 23-Apr-26 09:47 cumm/include/tensorview/gemm/core/constants.h
+-rw-rw-rw-  2.0 fat     1074 b- defN 23-Apr-26 09:47 cumm/include/tensorview/gemm/core/nvrtc_bases.h
+-rw-rw-rw-  2.0 fat     2164 b- defN 23-Apr-26 09:47 cumm/include/tensorview/gemm/core/nvrtc_params.h
+-rw-rw-rw-  2.0 fat    14835 b- defN 23-Apr-26 09:47 cumm/include/tensorview/gemm/core/params.h
+-rw-rw-rw-  2.0 fat     4051 b- defN 23-Apr-26 09:47 cumm/include/tensorview/gemm/core/utils.h
+-rw-rw-rw-  2.0 fat      815 b- defN 23-Apr-26 09:47 cumm/include/tensorview/gemm/dtypes/all.h
+-rw-rw-rw-  2.0 fat    13773 b- defN 23-Apr-26 09:47 cumm/include/tensorview/gemm/dtypes/bfloat16.h
+-rw-rw-rw-  2.0 fat      647 b- defN 23-Apr-26 09:47 cumm/include/tensorview/gemm/dtypes/common.h
+-rw-rw-rw-  2.0 fat    14986 b- defN 23-Apr-26 09:47 cumm/include/tensorview/gemm/dtypes/complex.h
+-rw-rw-rw-  2.0 fat    34614 b- defN 23-Apr-26 09:47 cumm/include/tensorview/gemm/dtypes/float8.h
+-rw-rw-rw-  2.0 fat      935 b- defN 23-Apr-26 09:47 cumm/include/tensorview/gemm/dtypes/fp_nvrtc.h
+-rw-rw-rw-  2.0 fat    21572 b- defN 23-Apr-26 09:47 cumm/include/tensorview/gemm/dtypes/half.h
+-rw-rw-rw-  2.0 fat     6042 b- defN 23-Apr-26 09:47 cumm/include/tensorview/gemm/dtypes/subint.h
+-rw-rw-rw-  2.0 fat    13276 b- defN 23-Apr-26 09:47 cumm/include/tensorview/gemm/dtypes/tf32.h
+-rw-rw-rw-  2.0 fat     7706 b- defN 23-Apr-26 09:47 cumm/include/tensorview/gemm/dtypes/uint128.h
+-rw-rw-rw-  2.0 fat     1749 b- defN 23-Apr-26 09:47 cumm/include/tensorview/gemm/math/activation.h
+-rw-rw-rw-  2.0 fat      725 b- defN 23-Apr-26 09:47 cumm/include/tensorview/gemm/math/all.h
+-rw-rw-rw-  2.0 fat    45005 b- defN 23-Apr-26 09:47 cumm/include/tensorview/gemm/math/functional.h
+-rw-rw-rw-  2.0 fat    75746 b- defN 23-Apr-26 09:47 cumm/include/tensorview/gemm/math/numeric_convert.h
+-rw-rw-rw-  2.0 fat      707 b- defN 23-Apr-26 09:47 cumm/include/tensorview/hash/all.cu.h
+-rw-rw-rw-  2.0 fat      597 b- defN 23-Apr-26 09:47 cumm/include/tensorview/hash/all.h
+-rw-rw-rw-  2.0 fat     2512 b- defN 23-Apr-26 09:47 cumm/include/tensorview/hash/dense.cu.h
+-rw-rw-rw-  2.0 fat     8727 b- defN 23-Apr-26 09:47 cumm/include/tensorview/hash/hash.cu.h
+-rw-rw-rw-  2.0 fat     3382 b- defN 23-Apr-26 09:47 cumm/include/tensorview/hash/hash_core.h
+-rw-rw-rw-  2.0 fat     8559 b- defN 23-Apr-26 09:47 cumm/include/tensorview/hash/hash_functions.h
+-rw-rw-rw-  2.0 fat    16464 b- defN 23-Apr-26 09:47 cumm/include/tensorview/hash/linear.cu.h
+-rw-rw-rw-  2.0 fat      739 b- defN 23-Apr-26 09:47 cumm/include/tensorview/hash/multilinear.cu.h
+-rw-rw-rw-  2.0 fat     6056 b- defN 23-Apr-26 09:47 cumm/include/tensorview/hash/ops.h
+-rw-rw-rw-  2.0 fat     8754 b- defN 23-Apr-26 09:47 cumm/include/tensorview/io/jsonarray.h
+-rw-rw-rw-  2.0 fat      679 b- defN 23-Apr-26 09:47 cumm/include/tensorview/math/all.h
+-rw-rw-rw-  2.0 fat     1020 b- defN 23-Apr-26 09:47 cumm/include/tensorview/math/array_ops.h
+-rw-rw-rw-  2.0 fat    17043 b- defN 23-Apr-26 09:47 cumm/include/tensorview/math/fastmath.h
+-rw-rw-rw-  2.0 fat      943 b- defN 23-Apr-26 09:47 cumm/include/tensorview/math/scalar.h
+-rw-rw-rw-  2.0 fat      652 b- defN 23-Apr-26 09:47 cumm/include/tensorview/parallel/all.h
+-rw-rw-rw-  2.0 fat    12654 b- defN 23-Apr-26 09:47 cumm/include/tensorview/parallel/kernel1d.h
+-rw-rw-rw-  2.0 fat     2821 b- defN 23-Apr-26 09:47 cumm/include/tensorview/parallel/map.h
+-rw-rw-rw-  2.0 fat     1422 b- defN 23-Apr-26 09:47 cumm/include/tensorview/parallel/ops.h
+-rw-rw-rw-  2.0 fat      625 b- defN 23-Apr-26 09:47 cumm/include/tensorview/profile/all.h
+-rw-rw-rw-  2.0 fat    12145 b- defN 23-Apr-26 09:47 cumm/include/tensorview/profile/cuda_profiler.h
+-rw-rw-rw-  2.0 fat   932454 b- defN 23-Apr-26 09:47 cumm/include/tensorview/thirdparty/nlohmann/json.hpp
+-rw-rw-rw-  2.0 fat    12179 b- defN 23-Apr-26 09:47 cumm/include/tensorview/thirdparty/tsl/robin_growth_policy.h
+-rw-rw-rw-  2.0 fat    55430 b- defN 23-Apr-26 09:47 cumm/include/tensorview/thirdparty/tsl/robin_hash.h
+-rw-rw-rw-  2.0 fat    29219 b- defN 23-Apr-26 09:47 cumm/include/tensorview/thirdparty/tsl/robin_map.h
+-rw-rw-rw-  2.0 fat    24253 b- defN 23-Apr-26 09:47 cumm/include/tensorview/thirdparty/tsl/robin_set.h
+-rw-rw-rw-  2.0 fat     1416 b- defN 23-Apr-26 09:47 cumm/include/tensorview/utility/tuplehash.h
+-rw-rw-rw-  2.0 fat    21726 b- defN 23-Apr-26 09:47 cumm/inliner/__init__.py
+-rw-rw-rw-  2.0 fat    25379 b- defN 23-Apr-26 09:47 cumm/nvrtc/__init__.py
+-rw-rw-rw-  2.0 fat     1240 b- defN 23-Apr-26 09:47 cumm/nvrtc/dev.py
+-rw-rw-rw-  2.0 fat      589 b- defN 23-Apr-26 09:47 cumm/services/__init__.py
+-rw-rw-rw-  2.0 fat     1041 b- defN 23-Apr-26 09:47 cumm/services/nvrtc.py
+-rw-rw-rw-  2.0 fat    22874 b- defN 23-Apr-26 09:47 cumm/tensorview/__init__.py
+-rw-rw-rw-  2.0 fat     2657 b- defN 23-Apr-26 09:47 cumm/tensorview/creator.py
+-rw-rw-rw-  2.0 fat     1038 b- defN 23-Apr-26 09:47 cumm/tensorview/gemm.py
+-rw-rw-rw-  2.0 fat     9460 b- defN 23-Apr-26 09:47 cumm/tensorview/tvio.py
+-rw-rw-rw-  2.0 fat      134 b- defN 23-Apr-26 09:47 cumm/tensorview/utils.py
+-rw-rw-rw-  2.0 fat    11536 b- defN 23-Apr-26 10:12 cumm_cu120-0.4.9.dist-info/LICENSE
+-rw-rw-rw-  2.0 fat     6392 b- defN 23-Apr-26 10:12 cumm_cu120-0.4.9.dist-info/METADATA
+-rw-rw-rw-  2.0 fat      100 b- defN 23-Apr-26 10:12 cumm_cu120-0.4.9.dist-info/WHEEL
+-rw-rw-rw-  2.0 fat       13 b- defN 23-Apr-26 10:10 cumm_cu120-0.4.9.dist-info/top_level.txt
+-rw-rw-r--  2.0 fat    19293 b- defN 23-Apr-26 10:12 cumm_cu120-0.4.9.dist-info/RECORD
+217 files, 4920780 bytes uncompressed, 1078214 bytes compressed:  78.1%
```

## zipnote {}

```diff
@@ -630,23 +630,23 @@
 
 Filename: cumm/tensorview/tvio.py
 Comment: 
 
 Filename: cumm/tensorview/utils.py
 Comment: 
 
-Filename: cumm_cu120-0.4.8.dist-info/LICENSE
+Filename: cumm_cu120-0.4.9.dist-info/LICENSE
 Comment: 
 
-Filename: cumm_cu120-0.4.8.dist-info/METADATA
+Filename: cumm_cu120-0.4.9.dist-info/METADATA
 Comment: 
 
-Filename: cumm_cu120-0.4.8.dist-info/WHEEL
+Filename: cumm_cu120-0.4.9.dist-info/WHEEL
 Comment: 
 
-Filename: cumm_cu120-0.4.8.dist-info/top_level.txt
+Filename: cumm_cu120-0.4.9.dist-info/top_level.txt
 Comment: 
 
-Filename: cumm_cu120-0.4.8.dist-info/RECORD
+Filename: cumm_cu120-0.4.9.dist-info/RECORD
 Comment: 
 
 Zip file comment:
```

## cumm/__version__.py

```diff
@@ -1 +1 @@
-__version__ = '0.4.8'
+__version__ = '0.4.9'
```

## cumm/common.py

```diff
@@ -314,15 +314,15 @@
         self.add_include("thrust/unique.h")
         # workaround for windows CI, thrust may not exist in windows CUDA
         thrust_include = os.getenv("CUMM_THRUST_INCLUDE", "")
         if thrust_include:
             self.build_meta.add_public_includes(thrust_include)
 
 
-class PyTorchLib(pccm.Class):
+class PyTorchLibNoPybind(pccm.Class):
     def __init__(self):
         super().__init__()
         spec = importlib.util.find_spec("torch")
         if spec is None:
             raise ValueError(
                 "you need to install torch python")
         origin = Path(spec.origin)
@@ -333,22 +333,24 @@
         self.build_meta.add_public_includes(str(libtorch / "include/torch/csrc/api/include"))
         torch_lib_paths = [str(libtorch / "lib")]
         torch_libs = ["c10", "torch", 'torch_cpu', 'torch_python']
         torch_cuda_libs = ["c10_cuda", "torch_cuda"]
         self.build_meta.libraries.extend(torch_libs + torch_cuda_libs)
         self.build_meta.libpaths.extend(torch_lib_paths)
         self.build_meta.add_public_cflags("nvcc,clang++,g++", "-D_GLIBCXX_USE_CXX11_ABI=0")
-
         self.add_include("torch/script.h")
-        self.add_include("torch/extension.h") # include this to add pybind for torch.Tensor
-
         self.add_include("ATen/cuda/CUDAContext.h")
         self.add_include("ATen/ATen.h")
-        self.add_include("tensorview/torch_utils.h")
 
+class PyTorchLib(pccm.Class):
+    def __init__(self):
+        super().__init__()
+        self.add_dependency(PyTorchLibNoPybind)
+        self.add_include("torch/extension.h") # include this to add pybind for torch.Tensor
+        self.add_include("tensorview/torch_utils.h")
 
 class TensorView(pccm.Class):
     def __init__(self):
         super().__init__()
         # any project depend on TensorView will add global nvcc flags:
         self.build_meta.add_global_cflags("nvcc", "--expt-relaxed-constexpr")
         self.build_meta.add_global_cflags("cl",  "/O2")
@@ -594,26 +596,33 @@
 
 class TensorViewNVRTC(pccm.Class):
     """a class that contains all tensorview features with nvrtc support.
     """
     def __init__(self):
         super().__init__()
         self.add_include("tensorview/core/all.h")
+        self.add_include("tensorview/tensorview.h")
         self.add_include("tensorview/core/arrayops/simple.h")
         if not CUMM_CPU_ONLY_BUILD:
             # here we can't depend on GemmKernelFlags
             # because nvrtc don't support regular arch flags.
             include, lib64 = _get_cuda_include_lib()
             self.build_meta.add_public_includes(include, TENSORVIEW_INCLUDE_PATH)
             self.add_include("tensorview/cuda/kernel_utils.h")
             self.build_meta.add_public_cflags("nvcc", "-DTV_CUDA")
             # if compat.InLinux:
             #     nvrtc_include = PACKAGE_ROOT / "nvrtc_include"
             #     self.build_meta.add_public_includes(nvrtc_include)
 
+class TensorViewViewClass(pccm.Class):
+    """a class that contains tensorview/tensorview.h.
+    """
+    def __init__(self):
+        super().__init__()
+        self.add_include("tensorview/tensorview.h")
 
 class TensorViewCore(pccm.Class):
     def __init__(self):
         super().__init__()
         self.add_dependency(TensorViewHeader)
         self.add_include("tensorview/core/all.h")
         self.add_include("tensorview/core/arrayops/simple.h")
@@ -725,7 +734,37 @@
 
 class CppTimer(pccm.Class):
     def __init__(self):
         super().__init__()
         self.add_include("tensorview/profile/cuda_profiler.h")
         self.build_meta.add_public_cflags("g++,clang++,nvcc", "-DTV_USE_LIBRT")
         self.build_meta.add_libraries("rt")
+
+class TensorViewCPULLVM(pccm.Class):
+    def __init__(self):
+        super().__init__()
+        self.build_meta.add_public_includes(TENSORVIEW_INCLUDE_PATH)
+        self.add_include("array")
+
+        self.add_include("tensorview/core/all.h")
+        self.add_include("tensorview/tensor.h")
+        self.add_include("tensorview/check.h")
+        self.add_include("tensorview/profile/all.h")
+        # self.build_meta.add_global_cflags("g++,clang++", "-g")
+        # currently llvmlite can't handle iostream, so
+        # we must disable it by -DTV_LLVM_JIT for tensorview library
+        self.build_meta.add_global_cflags("g++,clang++", "-DTV_LLVM_JIT")
+
+class TensorViewLLVM(pccm.Class):
+    def __init__(self):
+        super().__init__()
+        self.build_meta.add_global_cflags("nvcc", "--expt-relaxed-constexpr")
+        self.build_meta.add_global_cflags("cl",  "/O2")
+        self.build_meta.add_global_cflags("g++,clang++", "-O3")
+
+        if not CUMM_CPU_ONLY_BUILD:
+            self.add_dependency(CUDALibs, TensorViewCPULLVM)
+            self.build_meta.add_public_cflags("nvcc,clang++,g++", "-DTV_CUDA")
+            self.build_meta.add_public_cflags("cl", "/DTV_CUDA")
+        else:
+            self.add_dependency(TensorViewCPULLVM)
+
```

## cumm/tensorview_bind.py

```diff
@@ -500,14 +500,15 @@
     .def("set_max_dynamic_shared_size_bytes", &tv::NVRTCModule::set_max_dynamic_shared_size_bytes, py::arg("name"), py::arg("size"))
     .def("set_preferred_smem_carveout", &tv::NVRTCModule::set_preferred_smem_carveout, py::arg("name"), py::arg("carveout"))
     .def("run_kernel", &tv::NVRTCModule::run_kernel);
 
   py::enum_<tv::NVRTCModule::ArgType>(nvrtc_m, "ArgType")
       .value("kTensor", tv::NVRTCModule::ArgType::kTensor)
       .value("kArray", tv::NVRTCModule::ArgType::kArray)
+      .value("kTensorView", tv::NVRTCModule::ArgType::kTensorView)
       .export_values();
 
   py::class_<tv::Tensor, std::shared_ptr<tv::Tensor>>(m, "Tensor")
     .def(py::init([](std::vector<int64_t> shape, int dtype, int device, bool pinned, bool managed) {
         return tv::Tensor(tv::TensorShape(shape), tv::DType(dtype), device, pinned, managed);
     }), py::arg("shape"), py::arg("dtype") = 0, py::arg("device") = -1, py::arg("pinned") = false, py::arg("managed") = false)
     .def(py::init([]() {
```

## cumm/tensorview_bind_anno.pyi

```diff
@@ -145,15 +145,15 @@
     @staticmethod
     def from_binary(buffer: bytes) -> "NVRTCProgram":
         ...
 
 class NVRTCModule:
     kTensor = 0
     kArray = 1
-    kScalar = 2
+    kTensorView = 2
 
     @overload
     def __init__(self,
                  code: str,
                  headers: Dict[str, str] = {},
                  opts: List[str] = [],
                  program_name: str = "kernel",
```

## cumm/core_cc/tensorview_bind.pyi

```diff
@@ -150,15 +150,15 @@
     @staticmethod
     def from_binary(buffer: bytes) -> "NVRTCProgram":
         ...
 
 class NVRTCModule:
     kTensor = 0
     kArray = 1
-    kScalar = 2
+    kTensorView = 2
 
     @overload
     def __init__(self,
                  code: str,
                  headers: Dict[str, str] = {},
                  opts: List[str] = [],
                  program_name: str = "kernel",
```

## cumm/include/tensorview/check.h

```diff
@@ -7,15 +7,15 @@
 //     http://www.apache.org/licenses/LICENSE-2.0
 // 
 // Unless required by applicable law or agreed to in writing, software
 // distributed under the License is distributed on an "AS IS" BASIS,
 // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 // See the License for the specific language governing permissions and
 // limitations under the License.
-
+#pragma once
 #include "tensor.h"
 /*
 check_eq_dtype(a, b, c)
 check_eq_shape(a, b, c)
 check_eq_device(a, b, c)
 
 check_shape(a, {-1, 2})
```

## cumm/include/tensorview/tensor.h

```diff
@@ -114,14 +114,20 @@
 #if (CUDA_VERSION >= 11080 && defined(TV_CUDA))
 #include <cuda_fp8.h>
 #endif
 
 #include <random>
 
 namespace tv {
+
+enum DeviceType {
+  kDeviceCPU = -1,
+  kDeviceCUDA = 0,
+};
+
 namespace detail {
 
 using dtype_collection_t =
     mp_list_c<int, float32, int32, int16, int8, float64, bool_, uint8, float16,
               int64, uint16, uint32, uint64>;
 
 #if defined(TV_CUDA) && CUDA_VERSION < 11000
@@ -679,75 +685,81 @@
         shape_.size() * detail::sizeof_dtype(dtype_), -1, false, pinned);
     writeable_ = true;
     std::copy(first, second, data_ptr<T>());
   }
 
   template <typename T, int Rank = -1,
             template <class> class PtrTraits = DefaultPtrTraits,
-            typename Tindex = TV_GLOBAL_INDEX>
+            typename Tindex = TV_GLOBAL_INDEX,
+            bool DoTypeCheck = true>
   decltype(auto) tview() const {
     static_assert(Rank == -1 || Rank > 0, "error");
-    template_dtype_check<T>();
+    if (DoTypeCheck){
+      template_dtype_check<T>();
+    }
     return if_constexpr<(Rank > 0)>(
         [&](auto _) {
           // detail::_if_constexpr_workaround<Rank, (Rank > 0)> _val;
           // TV_ASSERT_RT_ERR(_(_val).value == ndim(), "error");
           ShapeBase<Rank == -1 ? TV_MAX_DIM : Rank, Tindex> shape(_(Rank)),
               stride(_(Rank));
           for (int i = 0; i < Rank; ++i) {
             shape[i] = shape_[i];
             stride[i] = stride_[i];
           }
           return TensorView<const std::remove_const_t<T>, Rank, PtrTraits,
                             Tindex>(
-              reinterpret_cast<const std::remove_const_t<T> *>(this->data<T>()),
+              reinterpret_cast<const std::remove_const_t<T> *>(this->data<T, DoTypeCheck>()),
               _(shape), _(stride));
         },
         [&](auto _) {
           ShapeBase<TV_MAX_DIM, Tindex> shape(this->ndim()),
               stride(this->ndim());
           for (int i = 0; i < int(this->ndim()); ++i) {
             shape[i] = shape_[i];
             stride[i] = stride_[i];
           }
           return TensorView<const std::remove_const_t<T>, Rank, PtrTraits,
                             Tindex>(
-              reinterpret_cast<const std::remove_const_t<T> *>(this->data<T>()),
+              reinterpret_cast<const std::remove_const_t<T> *>(this->data<T, DoTypeCheck>()),
               _(shape), _(stride));
         });
   }
 
   template <typename T, int Rank = -1,
             template <class> class PtrTraits = DefaultPtrTraits,
-            typename Tindex = TV_GLOBAL_INDEX>
+            typename Tindex = TV_GLOBAL_INDEX,
+            bool DoTypeCheck = true>
   decltype(auto) tview() {
     static_assert(Rank == -1 || Rank > 0, "error");
-    template_dtype_check<T>();
+    if (DoTypeCheck){
+      template_dtype_check<T>();
+    }
     return if_constexpr<(Rank > 0)>(
         [&](auto _) {
           // detail::_if_constexpr_workaround<Rank, (Rank > 0)> _val;
           // TV_ASSERT_RT_ERR(_(_val).value == ndim(), "error");
           ShapeBase<Rank == -1 ? TV_MAX_DIM : Rank, Tindex> shape(_(Rank)),
               stride(_(Rank));
           for (int i = 0; i < Rank; ++i) {
             shape[i] = shape_[i];
             stride[i] = stride_[i];
           }
           return TensorView<T, Rank, PtrTraits, Tindex>(
-              reinterpret_cast<T *>(this->data<T>()), _(shape), _(stride));
+              reinterpret_cast<T *>(this->data<T, DoTypeCheck>()), _(shape), _(stride));
         },
         [&](auto _) {
           ShapeBase<TV_MAX_DIM, Tindex> shape(this->ndim()),
               stride(this->ndim());
           for (int i = 0; i < int(this->ndim()); ++i) {
             shape[i] = shape_[i];
             stride[i] = stride_[i];
           }
           return TensorView<T, Rank, PtrTraits, Tindex>(
-              reinterpret_cast<T *>(this->data<T>()), _(shape), _(stride));
+              reinterpret_cast<T *>(this->data<T, DoTypeCheck>()), _(shape), _(stride));
         });
   }
 
   Tensor view(TensorShape shape) const {
     TensorShape newshape = shape;
     bool found_minus_1 = false;
     for (size_t i = 0; i < newshape.ndim(); ++i) {
@@ -1182,30 +1194,34 @@
     Dispatch<float_types_t>()(dtype_, [&](auto I) -> void {
       using T = TV_DECLTYPE(I);
       fill_template_<T>(val, ctx);
     });
     return *this;
   }
 
-  template <typename T> T *data() {
+  template <typename T, bool DoTypeCheck = true> T *data() {
     if (empty()) {
       return nullptr;
     }
-    template_dtype_check<T>();
+    if (DoTypeCheck){
+      template_dtype_check<T>();
+    }
     if (!std::is_const<T>::value){
       writable_check();
     }
     return reinterpret_cast<T *>(raw_data(false));
   }
 
-  template <typename T> const T *data() const {
+  template <typename T, bool DoTypeCheck = true> const T *data() const {
     if (empty()) {
       return nullptr;
     }
-    template_dtype_check<T>();
+    if (DoTypeCheck){
+      template_dtype_check<T>();
+    }
     return reinterpret_cast<const T *>(raw_data());
   }
 
   template <typename T> T *data_ptr() { return data<T>(); }
 
   template <typename T> const T *data_ptr() const { return data<T>(); }
```

## cumm/include/tensorview/tensorview.h

```diff
@@ -9,52 +9,63 @@
 // Unless required by applicable law or agreed to in writing, software
 // distributed under the License is distributed on an "AS IS" BASIS,
 // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 // See the License for the specific language governing permissions and
 // limitations under the License.
 
 #pragma once
-#include "common.h"
 #include "core/const_ops.h"
-#include "dtypes.h"
 #include "mp_helper.h"
 
 #include "core/vecarray.h"
 
 #include "core/defs.h"
 
+#ifdef __CUDACC_RTC__
+#include <tensorview/core/nvrtc_std.h>
+#else
+
+#include "common.h"
+#include "dtypes.h"
 #include "prettyprint.h"
 #include <algorithm>
 #include <cassert>
-
 #include <cstdlib>
-#include <iostream>
 #include <iterator>
 #include <memory>
 #include <sstream>
 #include <type_traits>
 #include <vector>
+#endif
+
 #ifdef TV_CUDA
-#include <cuda.h>
+
 #include <cuda_fp16.h>
+#ifndef __CUDACC_RTC__
+
+#include <cuda.h>
 #include <cuda_runtime_api.h>
 #endif
+#endif
 #if (CUDA_VERSION >= 11000 && defined(TV_CUDA))
 #include <cuda_bf16.h>
 #endif
 
 namespace tv {
 
 #ifdef TV_CUDA
+#ifndef __CUDACC_RTC__
+
 struct GPU {
   GPU(cudaStream_t s = 0) : mStream(s) {}
   virtual cudaStream_t getStream() const { return mStream; }
   cudaStream_t mStream = 0;
 };
 #endif
+#endif
 struct CPU {};
 
 template <typename T> struct DefaultPtrTraits { typedef T *type; };
 
 #if defined(__CUDACC__) || defined(__HIPCC__)
 template <typename T> struct RestrictPtrTraits {
   typedef T *__restrict__ type;
@@ -142,22 +153,23 @@
   TV_HOST_DEVICE_INLINE ShapeBase(const ShapeBase<MaxDim> &shape) {
     TV_ASSERT(shape.ndim() <= MaxDim);
     for (size_t i = 0; i < shape.ndim(); ++i) {
       this->array_[i] = shape[i];
     }
     this->size_ = shape.ndim();
   }
+#ifndef __CUDACC_RTC__
   template <typename Iterator, typename = detail::_RequireInputIter<Iterator>>
   ShapeBase(Iterator first, Iterator last)
       : vecarray<Tindex, MaxDim>(first, last) {}
   ShapeBase(const std::vector<int32_t> &arr)
       : vecarray<Tindex, MaxDim>(arr.begin(), arr.end()) {}
   ShapeBase(const std::vector<int64_t> &arr)
       : vecarray<Tindex, MaxDim>(arr.begin(), arr.end()) {}
-
+#endif
   TV_HOST_DEVICE ShapeBase<MaxDim, Tindex> &
   operator=(const ShapeBase<MaxDim, Tindex> &shape) {
     TV_ASSERT(shape.ndim() <= MaxDim);
     for (size_t i = 0; i < shape.ndim(); ++i) {
       this->array_[i] = shape[i];
     }
     this->size_ = shape.ndim();
@@ -259,14 +271,15 @@
       p *= this->array_[i];
     }
     return res;
   }
 };
 
 using Shape = ShapeBase<TV_MAX_DIM, TV_GLOBAL_INDEX>;
+#ifndef __CUDACC_RTC__
 
 template <class... Inds>
 TV_HOST_DEVICE_INLINE unsigned rowArrayIdx(std::vector<TV_GLOBAL_INDEX> &shape,
                                            Inds... indexes) {
   unsigned offset = 0;
   unsigned m = 1;
   TV_GLOBAL_INDEX indexes_vec[sizeof...(indexes)] = {indexes...};
@@ -287,15 +300,15 @@
   TV_GLOBAL_INDEX m = 1;
   for (int i = shape.size() - 1; i >= 0; --i) {
     offset += m * indexes_vec[i];
     m *= shape[i];
   }
   return offset;
 }
-
+#endif
 template <class... Inds>
 TV_HOST_DEVICE_INLINE TV_GLOBAL_INDEX rowArrayIdx(const Shape &shape,
                                                   Inds... indexes) {
   TV_GLOBAL_INDEX offset = 0;
   TV_GLOBAL_INDEX m = 1;
   TV_GLOBAL_INDEX indexes_vec[sizeof...(indexes)] = {indexes...};
   TV_PRAGMA_UNROLL
@@ -678,14 +691,15 @@
       : ptr_(ptr), shape_(shape), stride_(shape.stride_rowmajor()) {}
   explicit TV_HOST_DEVICE_INLINE TensorView(ptr_t ptr, tv_shape_t shape,
                                             tv_shape_t stride)
       : ptr_(ptr), shape_(shape), stride_(stride) {}
 
   template <typename T2 = T,
             typename = typename std::enable_if_t<!std::is_const<T2>::value>>
+  TV_HOST_DEVICE_INLINE
   operator std::enable_if_t<!std::is_const<T2>::value, const_type>() {
     return const_type(ptr_, shape_);
   } // conversion function
 
   template <class... Inds>
   TV_HOST_DEVICE_INLINE T &operator()(Inds... inds) const {
     static_assert(Rank == -1 || sizeof...(inds) == Rank, "error");
@@ -867,14 +881,16 @@
   TV_HOST_DEVICE_INLINE
   TensorView<T, (Rank == -1 ? -1 : Rank - 1), PtrTraits, Tindex>
   squeeze(int dim) const {
     return TensorView<T, (Rank == -1 ? -1 : Rank - 1), PtrTraits, Tindex>(
         ptr_, shape_.squeeze < Rank == -1 ? TV_MAX_DIM : Rank - 1 > (dim));
   }
   TV_HOST_DEVICE_INLINE size_t size() const { return shape_.size(); }
+
+#ifndef __CUDACC_RTC__
   template <typename Os>
   std::string repr(Os &ss, int limit = 1000, int limit_axis = 6) const {
     if (empty())
       return "";
     if (shape_.ndim() == 0) {
       ss << "Tensor[" << type_s<T> << "]" << std::endl;
       ss << *ptr_;
@@ -940,26 +956,27 @@
     }
     return ss.str();
   }
   std::string repr() const {
     std::ostringstream ss;
     return repr(ss);
   }
-
+#endif
 protected:
   template <typename T1> TV_HOST_DEVICE_INLINE Slice to_slice(T1 s) const {
     return Slice{int(s), -1, -1};
   }
 
   TV_HOST_DEVICE_INLINE Slice to_slice(Slice s) const { return Slice(s); }
 
   ptr_t ptr_ = nullptr;
   tv_shape_t shape_;
   tv_shape_t stride_;
 };
+#ifndef __CUDACC_RTC__
 
 template <typename T> TensorView<T> vector2tv(std::vector<T> &arr) {
   return TensorView<T>(arr.data(), {arr.size()});
 }
 
 template <typename T>
 TensorView<T> vector2tv(std::vector<T> &arr, Shape shape) {
@@ -1104,9 +1121,9 @@
                          detail::type_printf_format_v<Traw>);
 }
 template <typename T>
 TV_HOST_DEVICE void printTensorView(const T *ptr, Shape shape,
                                     const char *format) {
   return printTensorView(TensorView<const T>(ptr, shape), format);
 }
-
+#endif
 } // namespace tv
```

## cumm/include/tensorview/core/common.h

```diff
@@ -9,29 +9,34 @@
 // Unless required by applicable law or agreed to in writing, software
 // distributed under the License is distributed on an "AS IS" BASIS,
 // WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 // See the License for the specific language governing permissions and
 // limitations under the License.
 #pragma once
 #include "defs.h"
-#include <iostream>
 #include <sstream>
 #ifdef TV_USE_STACKTRACE
 #if defined(WIN32) || defined(_WIN32) ||                                       \
     defined(__WIN32) && !defined(__CYGWIN__)
 #define BOOST_STACKTRACE_USE_WINDBG
 #else
 // require linking with -ldl and -lbacktrace in linux
 #define BOOST_STACKTRACE_USE_BACKTRACE
 #endif
 #include <boost/stacktrace.hpp>
 #endif
 #ifdef TV_CUDA
 #include <cuda.h>
 #endif
+// llvmlite currently don't support iostream
+#ifndef TV_LLVM_JIT
+#include <iostream>
+#else 
+#include "printf2.h"
+#endif
 #if defined(TV_USE_BOOST_TYPEOF) ||                                            \
     (!defined(__clang__) && defined(CUDA_VERSION) && CUDA_VERSION >= 11000)
 // a workaround when built with cuda 11
 // #include <boost/typeof/typeof.hpp>
 // #define TV_DECLTYPE(x) BOOST_TYPEOF(x)
 // two options: use BOOST_TYPEOF or identity_t.
 // this is a nvcc bug, msvc/gcc/clang don't have this problem.
@@ -63,15 +68,20 @@
   }
   sstream_print<Sep>(ss, args...);
 }
 
 template <char Sep = ' ', class... TArgs> void ssprint(TArgs... args) {
   std::stringstream ss;
   sstream_print<Sep>(ss, args...);
+#ifndef TV_LLVM_JIT
   std::cout << ss.str() << std::endl;
+#else 
+  auto char_str = ss.str();
+  tv::printf2(char_str.c_str());
+#endif
 }
 
 #ifdef TV_USE_STACKTRACE
 #define TV_BACKTRACE_PRINT(ss)                                                 \
   ss << std::endl << boost::stacktrace::stacktrace();
 #elif defined(TV_USE_BACKWARD_TRACE)
 #define TV_BACKTRACE_PRINT(ss)                                                 \
```

## cumm/include/tensorview/core/nvrtc/type_traits.h

```diff
@@ -104,14 +104,41 @@
 template <typename _Tp> struct add_volatile { typedef _Tp volatile type; };
 
 /// add_cv
 template <typename _Tp> struct add_cv {
   typedef typename add_const<typename add_volatile<_Tp>::type>::type type;
 };
 
+template <typename _Tp> using remove_const_t = typename remove_const<_Tp>::type;
+
+/// Alias template for remove_volatile
+template <typename _Tp>
+using remove_volatile_t = typename remove_volatile<_Tp>::type;
+
+/// Alias template for remove_cv
+template <typename _Tp> using remove_cv_t = typename remove_cv<_Tp>::type;
+
+/// Alias template for add_const
+template <typename _Tp> using add_const_t = typename add_const<_Tp>::type;
+
+/// Alias template for add_volatile
+template <typename _Tp> using add_volatile_t = typename add_volatile<_Tp>::type;
+
+/// Alias template for add_cv
+template <typename _Tp> using add_cv_t = typename add_cv<_Tp>::type;
+/// is_const
+template <typename> struct is_const : public false_type {};
+
+template <typename _Tp> struct is_const<_Tp const> : public true_type {};
+
+/// is_volatile
+template <typename> struct is_volatile : public false_type {};
+
+template <typename _Tp> struct is_volatile<_Tp volatile> : public true_type {};
+
 template <typename _Tp, typename> struct __remove_pointer_helper {
   typedef _Tp type;
 };
 
 template <typename _Tp, typename _Up>
 struct __remove_pointer_helper<_Tp, _Up *> {
   typedef _Up type;
```

## cumm/include/tensorview/cuda/nvrtc.h

```diff
@@ -442,14 +442,16 @@
 #ifdef TV_CUDA
     if (module_ == nullptr) {
       load();
     }
     CUstream stream = reinterpret_cast<CUstream>(stream_int);
     std::vector<void *> params;
     std::vector<const void *> tensor_ptrs(args.size());
+    std::vector<tv::Tensor> tensor_view_datas;
+
     int cnt = 0;
     for (auto &arg : args) {
       auto &ten = std::get<0>(arg);
       auto arg_type = std::get<1>(arg);
       switch (arg_type) {
       case ArgType::kTensor: {
         if (ten.empty()) {
@@ -460,18 +462,33 @@
         }
         params.push_back(&tensor_ptrs[cnt]);
         cnt += 1;
         break;
       }
       case ArgType::kArray: {
         TV_ASSERT_INVALID_ARG(ten.device() == -1, "array tensor must be CPU");
+        // const check is performed in python
         params.push_back(const_cast<void *>(
             reinterpret_cast<const void *>(ten.const_raw_data())));
         break;
       }
+      case ArgType::kTensorView: {
+        TV_ASSERT_INVALID_ARG(ten.device() == 0 && ten.ndim() <= 10, "array tensor must be GPU and <= 10 dim");
+        tv::DispatchInt<tv::mp_list_int_range<1, 11>>()(ten.ndim(), [&](auto I){
+          constexpr auto V = int(I);
+          auto tview = ten.tview<const float, V, tv::DefaultPtrTraits, TV_GLOBAL_INDEX, false>();
+          using tview_t = std::decay_t<decltype(tview)>;
+          tv::Tensor storage = tv::empty({sizeof(tview_t)}, tv::uint8, tv::kDeviceCPU);
+          auto tview_data_ptr = reinterpret_cast<tview_t*>(storage.raw_data());
+          tview_data_ptr[0] = tview;
+          tensor_view_datas.push_back(storage);
+          params.push_back(storage.raw_data());
+        });
+        break;
+      }
       default:
         TV_THROW_RT_ERR("not implemented");
       }
     }
     auto k = kernel(name);
     if (smem_size >= (48 << 10)) {
       TV_CUDA_RESULT_CHECK_V2(wrapper_.cuDrvFuncSetAttribute(
```

## cumm/inliner/__init__.py

```diff
@@ -55,27 +55,29 @@
         },
 
     },
 
 
 """
 
+import contextlib
 import pccm
 from pccm.builder.inliner import InlineBuilder, InlineBuilderPlugin, PCCM_INLINE_NAMESPACE, PCCM_INLINE_FUNCTION_NAME
 from cumm.nvrtc import CummLLVMModule, CummNVRTCModule, CummNVRTCModuleBase, create_nvrtc_code
 from pathlib import Path
 from cumm.common import TensorViewKernel
 import enum
 from pccm.utils import get_qualname_of_type
 from typing import Any, Callable, Dict, List, Optional, Set, Tuple, Type, Union
 import numpy as np
 from cumm import dtypes, tensorview as tv
-from cumm.common import TensorViewNVRTC, GemmBasic
+from cumm.common import TensorViewNVRTC, GemmBasic, TensorViewViewClass
 from cumm.gemm.codeops import div_up
 from cumm.tensorview import nullcontext
+from ccimport import compat
 _TORCH_DTYPE_TO_TV: Dict[Any, int] = {}
 TORCH_TENSOR_NAME = "torch.Tensor"
 
 
 class LaunchParam:
     def __init__(self,
                  blocks: Tuple[int, ...],
@@ -154,14 +156,17 @@
 
     def get_cpp_type(self, obj: Any, user_arg: Optional[Any] = None) -> str:
         if get_qualname_of_type(type(obj)) == TORCH_TENSOR_NAME:
             obj = torch_tensor_to_tv(obj)
         prefix = ""
         if obj.is_readonly():
             prefix = "const "
+        if user_arg is not None and isinstance(user_arg, _NVRTCInlineParams):
+            if user_arg.capture_tensor_as_tview:
+                return f"tv::TensorView<{prefix}{dtypes.get_dtype_from_tvdtype(obj.dtype, True)}, {obj.ndim}>"
         return f"{prefix}{dtypes.get_dtype_from_tvdtype(obj.dtype, True)}*"
 
 
 _NPDTYPE_TO_LIST_TYPE_STR: Dict[np.dtype, str] = {
     np.dtype(np.float16): "__half",
     np.dtype(np.float32): "float",
     np.dtype(np.float64): "double",
@@ -186,47 +191,56 @@
                              name: str,
                              code: pccm.FunctionCode,
                              obj: Any,
                              user_arg: Optional[Any] = None) -> Optional[str]:
         return
 
     def type_conversion(self, obj: np.ndarray, user_arg: Optional[Any] = None):
+        # if isinstance(user_arg, _NVRTCInlineParams):
+        #     if user_arg.is_cpu:
+        #         return obj.reshape(-1).tolist()
+        assert obj.size <= 50, "we only support capture small numpy which will be passed by value to kernel"
         return obj.tolist()
 
     def get_cpp_type(self,
                      obj: np.ndarray,
-                     user_arg: Optional[Any] = None) -> str:
+                     user_arg: Optional[Any] = None) -> Union[str, Tuple[str, int]]:
         ndim = obj.ndim
         dtype = obj.dtype
         if dtype is None:
             dtype = obj.dtype
         cpp_type = _NPDTYPE_TO_LIST_TYPE_STR[dtype]
+        # if isinstance(user_arg, _NVRTCInlineParams):
+        #     if user_arg.is_cpu:
+        #         return cpp_type, obj.size
         array_type = ""
         array_type += "tv::array<" * ndim
         array_type += f"{cpp_type}, "
         shape_rev = obj.shape[::-1]
         array_type += ">, ".join(map(str, shape_rev))
-        return array_type + ">"
+        res = array_type + ">"
+        return res
 
 
 class _NVRTCInlineParams:
     def __init__(self,
                  mode: CUDAMode,
                  launch: tv.LaunchParam,
                  verbose: bool = False,
                  verbose_path: str = "",
                  measure_time: bool = False,
-                 is_cpu: bool = False) -> None:
+                 is_cpu: bool = False,
+                 capture_tensor_as_tview: bool = False) -> None:
         self.mode = mode
         self.launch = launch
         self.verbose = verbose
         self.verbose_path = verbose_path
         self.measure_time = measure_time
         self.is_cpu = is_cpu
-        
+        self.capture_tensor_as_tview = capture_tensor_as_tview
 
 
 _NVRTC_FUNC_NAME = f"{PCCM_INLINE_NAMESPACE}::{PCCM_INLINE_FUNCTION_NAME}"
 
 _DEFAULT_KERNEL_PLUGINS: Dict[str, InlineBuilderPlugin] = {
     "numpy.ndarray": NumpyPlugin(),
     TVTensorPlugin.QualifiedName: TVTensorPlugin(),
@@ -244,32 +258,38 @@
             index_name: str = "i",
             root: Optional[Path] = None,
             build_root: Optional[Path] = None,
             build_kwargs: Optional[Dict[str, Any]] = None,
             param_deps: Optional[List[pccm.ParameterizedClass]] = None,
             measure_build_time: bool = False,
             reload_when_code_change: bool = False,
-            remote_addr: str = ""):
+            remote_addr: str = "",
+            default_deps: Optional[List[Type[pccm.Class]]] = None):
         if plugins is None:
             plugins = _DEFAULT_KERNEL_PLUGINS
-        deps.extend([TensorViewNVRTC, GemmBasic])
+        if default_deps is None:
+            deps.extend([TensorViewNVRTC, GemmBasic])
+        else:
+            deps.extend(default_deps)
         if build_kwargs is None:
             build_kwargs = {}
         super().__init__(deps=deps,
                          plugins=plugins,
                          build_kwargs=build_kwargs,
                          root=root,
                          build_root=build_root,
                          param_deps=param_deps,
                          reload_when_code_change=reload_when_code_change)
         self.index_name = index_name
         self.maximum_1d_threads = 512
         self.measure_build_time = measure_build_time
         self._remote_addr = remote_addr
 
+    
+
     def get_nvrtc_module(self, name: str) -> Optional[CummNVRTCModule]:
         for k, v in self.modules.items():
             if name == k[1]:
                 return v.func
         return None
 
     def get_save_root(self,
@@ -280,39 +300,52 @@
         return Path()
 
     def get_base_class(self):
         return pccm.Class()
 
     def handle_container_code(self, code_str: str, code: pccm.FunctionCode,
                               arg: Optional[_NVRTCInlineParams]):
-        is_cpu = False 
+        is_cpu = False
         meta = pccm.cuda.CudaGlobalFunctionMeta(attrs=["__global__"])
 
         if arg is not None:
             is_cpu = arg.is_cpu
         if is_cpu:
             meta = pccm.cuda.ExternalFunctionMeta()
 
         if arg is None:
             code.raw(code_str)
             return meta
-        if arg.mode == CUDAMode.KernelRaw:
-            code.raw(code_str)
-            return meta
-        if not is_cpu:
-            with code.for_(
-                    f"auto {self.index_name} : tv::KernelLoopX<int>({_CUMM_KERNEL_1D_SIZE_NAME})"
-            ):
-                code.raw(code_str)
-        else:
-            with code.for_(
-                    f"size_t i = 0; i <{_CUMM_KERNEL_1D_SIZE_NAME}; ++i"
-            ):
+        trycatch_ctx = contextlib.nullcontext()
+        if is_cpu:
+            code.raw(f"""
+            int __pccm_error_code = 0;
+            """)
+            trycatch_ctx = code.block("try", end=f"""
+            }}catch (const std::exception& e){{
+                tv::printf2("LLVM Inline Function Exception!. Error:", e.what());
+                __pccm_error_code = 1;
+            }}
+            """)
+        with trycatch_ctx:
+            if arg.mode == CUDAMode.KernelRaw:
                 code.raw(code_str)
-            code.raw("return 0;")
+            else:
+                if not is_cpu:
+                    with code.for_(
+                            f"auto {self.index_name} : tv::KernelLoopX<int>({_CUMM_KERNEL_1D_SIZE_NAME})"
+                    ):
+                        code.raw(code_str)
+                else:
+                    with code.for_(
+                            f"size_t i = 0; i <{_CUMM_KERNEL_1D_SIZE_NAME}; ++i"
+                    ):
+                        code.raw(code_str)
+        if is_cpu:
+            code.raw("return __pccm_error_code;")
             code.ret("int")
         return meta
 
     def build(self,
               pccm_cls: pccm.Class,
               mod_root: Path,
               name: str,
@@ -324,37 +357,39 @@
             verbose = user_arg.verbose
             verbose_path = user_arg.verbose_path
         ctx = nullcontext()
         if self.measure_build_time:
             ctx = tv.measure_and_print(f"{name} nvrtc build time")
         # with tv.measure_and_print("INLINE"):
         params = create_nvrtc_code([pccm_cls])
-        is_cpu = False 
+        is_cpu = False
         if user_arg is not None:
             is_cpu = user_arg.is_cpu
         if self._remote_addr != "":
             # this should be used only you want to debug
             # different cuda version.
-            import tensorpc 
+            import tensorpc
             with tensorpc.RemoteManager(self._remote_addr) as robj:
                 mod = robj.remote_call("NVRTCCompiler.compile_nvrtc", params)
         else:
             with ctx:
                 if is_cpu:
+                    if not compat.InLinux:
+                        raise NotImplementedError("cpu jit only support linux")
                     mod = CummLLVMModule([pccm_cls],
-                                                verbose=verbose,
-                                                verbose_path=verbose_path)
+                                         verbose=verbose,
+                                         verbose_path=verbose_path)
                 else:
                     if verbose:
                         mod = CummNVRTCModule([pccm_cls],
-                                                verbose=verbose,
-                                                verbose_path=verbose_path)
+                                              verbose=verbose,
+                                              verbose_path=verbose_path)
                     else:
                         mod = CummNVRTCModuleBase.from_params(params)
-            
+
         return mod
 
     def run_func(self,
                  func: CummNVRTCModuleBase,
                  *args,
                  user_args: Optional[_NVRTCInlineParams] = None):
         assert user_args is not None
@@ -362,54 +397,108 @@
         return func.run_kernel(_NVRTC_FUNC_NAME, launch, *args)
 
     def kernel_raw(self,
                    name: str,
                    param: tv.LaunchParam,
                    code: Union[str, pccm.FunctionCode],
                    verbose_path: str = "",
-                   disable_cache: bool = False):
+                   disable_cache: bool = False,
+                   capture_tensor_as_tview: bool = False,
+                   *,
+                   _frame_cnt: int = 2):
         verbose = verbose_path != ""
         user_arg = _NVRTCInlineParams(CUDAMode.KernelRaw, param, verbose,
-                                      verbose_path)
+                                      verbose_path, capture_tensor_as_tview=capture_tensor_as_tview)
+        if capture_tensor_as_tview:
+            if not isinstance(code, pccm.FunctionCode):
+                code_pccm = pccm.code()
+                code_pccm.raw(code)
+                code = code_pccm
+            code.add_dependency(TensorViewViewClass)
         return self.inline(name,
                            code,
                            ".cu",
-                           _frame_cnt=2,
+                           _frame_cnt=_frame_cnt,
                            user_arg=user_arg,
                            disable_cache=disable_cache)
+    
+    def kernel_raw_capture_tview(self,
+                                name: str,
+                                param: tv.LaunchParam,
+                                code: Union[str, pccm.FunctionCode],
+                                verbose_path: str = "",
+                                disable_cache: bool = False):
+        """same as kernel_raw except all tensors (tv.Tensor, torch.Tensor)
+        are captured as tv::TensorView with shape/stride support inside kernel.
+        """
+        return self.kernel_raw(name=name, 
+                              param=param, 
+                              code=code, 
+                              verbose_path=verbose_path, 
+                              disable_cache=disable_cache, 
+                              capture_tensor_as_tview=True,
+                              _frame_cnt=3)
 
     def kernel_1d(self,
                   name: str,
                   num: int,
                   stream: int,
                   code: Union[str, pccm.FunctionCode],
                   verbose_path: str = "",
-                  disable_cache: bool = False):
+                  disable_cache: bool = False,
+                  capture_tensor_as_tview: bool = False,
+                  _frame_cnt: int = 2):
         verbose = verbose_path != ""
         num = int(num)
         user_arg = _NVRTCInlineParams(CUDAMode.Kernel1D,
                                       self.get_1d_param(num, stream=stream),
-                                      verbose, verbose_path)
+                                      verbose, verbose_path,
+                                      capture_tensor_as_tview=capture_tensor_as_tview)
         additional_args = {
             _CUMM_KERNEL_1D_SIZE_NAME: num,
         }
+        if capture_tensor_as_tview:
+            if not isinstance(code, pccm.FunctionCode):
+                code_pccm = pccm.code()
+                code_pccm.raw(code)
+                code = code_pccm
+            code.add_dependency(TensorViewViewClass)
         return self.inline(name,
                            code,
                            ".cu",
                            additional_args,
-                           _frame_cnt=2,
+                           _frame_cnt=_frame_cnt,
                            user_arg=user_arg,
                            disable_cache=disable_cache)
 
+    def kernel_1d_capture_tview(self,
+                                name: str,
+                                num: int,
+                                stream: int,
+                                code: Union[str, pccm.FunctionCode],
+                                verbose_path: str = "",
+                                disable_cache: bool = False):
+        """same as kernel_1d except all tensors (tv.Tensor, torch.Tensor)
+        are captured as tv::TensorView with shape/stride support inside kernel.
+        """
+        return self.kernel_1d(name=name, 
+                              num=num, 
+                              stream=stream, 
+                              code=code, 
+                              verbose_path=verbose_path, 
+                              disable_cache=disable_cache, 
+                              capture_tensor_as_tview=True,
+                              _frame_cnt=3)
+
     def cpu_kernel_1d(self,
-                  name: str,
-                  num: int,
-                  code: Union[str, pccm.FunctionCode],
-                  verbose_path: str = "",
-                  disable_cache: bool = False):
+                      name: str,
+                      num: int,
+                      code: Union[str, pccm.FunctionCode],
+                      verbose_path: str = "",
+                      disable_cache: bool = False):
         verbose = verbose_path != ""
         num = int(num)
         user_arg = _NVRTCInlineParams(CUDAMode.Kernel1D,
                                       self.get_1d_param(num, stream=0),
                                       verbose, verbose_path,
                                       is_cpu=True)
         additional_args = {
@@ -420,44 +509,51 @@
                            ".cu",
                            additional_args,
                            _frame_cnt=2,
                            user_arg=user_arg,
                            disable_cache=disable_cache)
 
     def cpu_kernel_raw(self,
-                   name: str,
-                #    param: tv.LaunchParam,
-                   code: Union[str, pccm.FunctionCode],
-                   verbose_path: str = "",
-                   disable_cache: bool = False):
+                       name: str,
+                       #    param: tv.LaunchParam,
+                       code: Union[str, pccm.FunctionCode],
+                       verbose_path: str = "",
+                       disable_cache: bool = False):
         verbose = verbose_path != ""
-        user_arg = _NVRTCInlineParams(CUDAMode.KernelRaw, 
-                    tv.LaunchParam((1,1,1), (1,1,1)), verbose,
-                    verbose_path, is_cpu=True)
+        user_arg = _NVRTCInlineParams(CUDAMode.KernelRaw,
+                                      tv.LaunchParam(
+                                          (1, 1, 1), (1, 1, 1)), verbose,
+                                      verbose_path, is_cpu=True)
         return self.inline(name,
                            code,
                            ".cu",
                            _frame_cnt=2,
                            user_arg=user_arg,
                            disable_cache=disable_cache)
 
+    def cpu_prepare_libraries(self, *libs: str):
+        import llvmlite.binding as llvm
+        for l in libs:
+            llvm.load_library_permanently(l)
+
     def get_1d_param(self, num: int, smem: int = 0, stream: int = 0):
         if num > self.maximum_1d_threads:
             threads = self.maximum_1d_threads
         else:
             threads = div_up(num, 32) * 32
         blocks = div_up(num, threads)
         return tv.LaunchParam((blocks, 1, 1), (threads, 1, 1), smem, stream)
 
 
 def main():
     import torch
     from cumm import tensorview as tv
     from cumm.common import TensorViewArrayLinalg, TensorViewNVRTCHashKernel
-    INLINE = NVRTCInlineBuilder([TensorViewArrayLinalg, TensorViewNVRTCHashKernel], reload_when_code_change=True)
+    INLINE = NVRTCInlineBuilder(
+        [TensorViewArrayLinalg, TensorViewNVRTCHashKernel], reload_when_code_change=True)
 
     print(1)
     a = tv.zeros([2], tv.float32, 0)
     print(2)
     INLINE.kernel_1d("hahaha", a.dim(0), 0, f"""
     $a[i] = 5;
     """)
```

## cumm/nvrtc/__init__.py

```diff
@@ -1,72 +1,112 @@
 import dataclasses
 from pathlib import Path
 import tempfile
-from typing import Any, Dict, List, Optional, Tuple, Union, TYPE_CHECKING
+from typing import Any, Dict, List, Optional, Set, Tuple, Union, TYPE_CHECKING
 import subprocess
 
 import pccm
 from ccimport import compat
 from pccm import Argument
 from pccm.core import CodeGenerator
 from pccm.core.buildmeta import BuildMeta
 from pccm.targets.cuda import CudaGlobalFunctionMeta
 from pccm.core import ExternalFunctionMeta
 import ctypes
 from cumm import PACKAGE_ROOT
 from cumm import tensorview as tv
 from cumm.common import TensorViewKernel, _get_cuda_include_lib
 from cumm.core_cc.tensorview_bind import Tensor
-import numpy as np 
+import numpy as np
 
 LLVM_IS_INITED = False
+LAZY_LOAD_LIBRARIES: Set[str] = set()
+
+LLVM_GLOBAL_ENGINE = None
 
 _cudadevrt_libname = "libcudadevrt.a"
 if compat.InWindows:
     _cudadevrt_libname = "cudadevrt.lib"
 
+
 def get_cudadevrt_path():
     _, lib64 = _get_cuda_include_lib()
     _cudadevrt_path_candidates = [
         PACKAGE_ROOT / "lib" / _cudadevrt_libname,  # pip package
         lib64 / _cudadevrt_libname,  # pip package
     ]
     for c in _cudadevrt_path_candidates:
         if c.exists():
             return c
     return None
 
+
 def cufilt(name: str):
     res = tv.cufilt(name)
     if res:
-        return res 
+        return res
     else:
         # if fail, use cu++filt.
         # in windows, gcc-style demangle isn't available.
         # so we can only use subprocess before cuda 11.4.
-        res = subprocess.check_output(["cu++filt", name]).decode("utf-8").strip()
-        return res 
+        res = subprocess.check_output(["cu++filt",
+                                       name]).decode("utf-8").strip()
+        return res
+
 
 def _lazy_load_llvm():
     import llvmlite.binding as llvm
     global LLVM_IS_INITED
+    global LLVM_GLOBAL_ENGINE
     if not LLVM_IS_INITED:
         llvm.initialize()
         llvm.initialize_native_target()
         llvm.initialize_native_asmprinter()  # yes, even this one
-        LLVM_IS_INITED = True 
+        # we need this for some std library
+        llvm.load_library_permanently("libstdc++.so.6")
+        llvm.load_library_permanently("libc.so.6")
+        LLVM_GLOBAL_ENGINE = create_execution_engine(False)
+
+        # llvm.load_library_permanently("libdl.so")
+        # llvm.load_library_permanently("librt.so")
+        # llvm.load_library_permanently("libpthread.so")
+
+        LLVM_IS_INITED = True
+
+
+def _lazy_load_lib_for_llvm(libs: List[str], libpaths: List[str]):
+    import llvmlite.binding as llvm
+    libpaths_p = [Path(p) for p in libpaths]
+    for l in libs:
+        lib_name = f"lib{l}.so"
+        if l not in LAZY_LOAD_LIBRARIES:
+            LAZY_LOAD_LIBRARIES.add(l)
+            try:
+                llvm.load_library_permanently(lib_name)
+            except RuntimeError:
+                loaded = False
+                for proot in libpaths_p:
+                    lib_candidate = proot / lib_name
+                    if lib_candidate.exists():
+                        llvm.load_library_permanently(str(lib_candidate))
+                        loaded = True
+                        break
+                if not loaded:
+                    raise
+
 
-def create_execution_engine():
+def create_execution_engine(lazy_load_llvm: bool):
     """
     Create an ExecutionEngine suitable for JIT code generation on
     the host CPU.  The engine is reusable for an arbitrary number of
     modules.
     """
     import llvmlite.binding as llvm
-    _lazy_load_llvm()
+    if lazy_load_llvm:
+        _lazy_load_llvm()
     # Create a target machine representing the host
     target = llvm.Target.from_default_triple()
     target_machine = target.create_target_machine()
     # And an execution engine with an empty backing module
     backing_mod = llvm.parse_assembly("")
     engine = llvm.create_mcjit_compiler(backing_mod, target_machine)
     return engine
@@ -84,14 +124,15 @@
     mod.verify()
     # Now add the module and make sure it is ready for execution
     engine.add_module(mod)
     engine.finalize_object()
     engine.run_static_constructors()
     return mod
 
+
 def compile_bitcode(engine, llvm_bitcode):
     """
     Compile the LLVM IR string with the given engine.
     The compiled module object is returned.
     """
     import llvmlite.binding as llvm
     _lazy_load_llvm()
@@ -100,31 +141,47 @@
     mod.verify()
     # Now add the module and make sure it is ready for execution
     engine.add_module(mod)
     engine.finalize_object()
     engine.run_static_constructors()
     return mod
 
+
 @dataclasses.dataclass
 class NVRTCModuleParams:
     code: str
     headers: Dict[str, str]
     opts: List[str]
     name_exprs: List[str]
     name_to_meta: Dict[str, tv.NVRTCKernelMeta]
     program_name: str = "kernel.cu"
     cudadevrt_path: str = ""
     includes: List[str] = dataclasses.field(default_factory=list)
+    libraries: List[str] = dataclasses.field(default_factory=list)
+    libpaths: List[str] = dataclasses.field(default_factory=list)
+    debug_code: str = ""
+
+def _unique_list_keep_order(seq: list):
+    if compat.Python3_7AndLater:
+        # https://www.peterbe.com/plog/fastest-way-to-uniquify-a-list-in-python-3.6
+        # only python 3.7 language std ensure the preserve-order dict
+        return list(dict.fromkeys(seq))
+    else:
+        # https://stackoverflow.com/questions/480214/how-do-you-remove-duplicates-from-a-list-whilst-preserving-order
+        seen = set()
+        seen_add = seen.add
+        return [x for x in seq if not (x in seen or seen_add(x))]
 
 def create_nvrtc_code(cus: List[pccm.Class],
-                 namespace_root: Optional[Union[str, Path]] = None,
-                 cudadevrt_path: str = "",
-                 custom_names: Optional[List[str]] = None,
-                 std: str = "c++14",
-                 cpu_code: bool = False) -> NVRTCModuleParams:
+                      namespace_root: Optional[Union[str, Path]] = None,
+                      cudadevrt_path: str = "",
+                      custom_names: Optional[List[str]] = None,
+                      std: str = "c++14",
+                      cpu_code: bool = False,
+                      add_arch_flag: bool = True) -> NVRTCModuleParams:
     cg = CodeGenerator([])
     user_cus = cg.build_graph(cus, namespace_root)
     # iterate cus and get all kernels
     name_to_meta: Dict[str, tv.NVRTCKernelMeta] = {}
     for cu in user_cus:
         cu_ns = cu.canonical_namespace
         for decl in cu._function_decls:
@@ -135,37 +192,42 @@
                 meta_cls = CudaGlobalFunctionMeta
             if isinstance(meta, meta_cls):
                 if decl.code.is_template():
                     # don't support template kernel
                     continue
                 # is global function. firstly check types
                 meta = tv.NVRTCKernelMeta(meta.name, cu_ns,
-                                            decl.code.arguments)
+                                          decl.code.arguments)
                 func_qualname = meta.name
                 if cu_ns:
                     func_qualname = f"{cu_ns}::{meta.name}"
                 name_to_meta[func_qualname] = meta
 
     # generate code for nvrtc
-    header_dict, _, _ = cg.code_generation(user_cus,
-                                            global_header_only=True)
+    outer_code = list(
+        pccm.core.CodeGenerator.generate_cu_code_v2(
+            cus[0], True, global_header_only=True)[0].values())[0].to_string()
+    header_dict, _, _ = cg.code_generation(user_cus, global_header_only=True)
     header_code_dict = {k: v.to_string() for k, v in header_dict.items()}
     final_code = ""
     for k, _ in header_dict.items():
         final_code += f"#include <{k}>\n"
     extern_build_meta = BuildMeta()
     for cu in user_cus:
         extern_build_meta += cu.build_meta
     # this function will call driver init
     opts = [f"-std={std}"]
     global_cflags = extern_build_meta.get_global_cflags()
     local_cflags = extern_build_meta.get_local_cflags()
     if not cpu_code:
-        arch = tv.get_compute_capability()
-        opts.append(f"--gpu-architecture=sm_{arch[0]}{arch[1]}")
+        if add_arch_flag:
+            # if we use CummNVRTCModule to compile ptx for optix, 
+            # we can't add arch flag
+            arch = tv.get_compute_capability()
+            opts.append(f"--gpu-architecture=sm_{arch[0]}{arch[1]}")
         if cudadevrt_path and Path(cudadevrt_path).exists():
             opts.append("--relocatable-device-code=true")
         if "nvcc" in global_cflags:
             opts.extend(global_cflags["nvcc"])
         if "nvcc" in local_cflags:
             opts.extend(local_cflags["nvcc"])
     else:
@@ -174,33 +236,43 @@
         if "clang++" in global_cflags:
             opts.extend(global_cflags["clang++"])
         if "g++" in local_cflags:
             opts.extend(local_cflags["g++"])
         if "clang++" in local_cflags:
             opts.extend(local_cflags["clang++"])
     # print(opts)
-    opts = list(set(opts))
-
-    includes = []
+    
+    opts = _unique_list_keep_order(opts)
+    includes: List[str] = []
     for inc in extern_build_meta.get_global_includes():
         opts.append("-I")
         opts.append(str(inc))
         includes.append(str(inc))
     for inc in extern_build_meta.get_local_includes():
         opts.append("-I")
         opts.append(str(inc))
         includes.append(str(inc))
     name_exprs = list(name_to_meta.keys())
     if custom_names is not None:
         name_exprs.extend(custom_names)
-    return NVRTCModuleParams(final_code, header_code_dict,
-        opts, name_exprs, name_to_meta, "kernel.cu", cudadevrt_path,
-        includes=includes)
+    return NVRTCModuleParams(final_code,
+                             header_code_dict,
+                             opts,
+                             name_exprs,
+                             name_to_meta,
+                             "kernel.cu",
+                             cudadevrt_path,
+                             includes=includes,
+                             libraries=extern_build_meta.libraries,
+                             libpaths=list(map(str, extern_build_meta.libpaths)),
+                             debug_code=outer_code)
+
 
 class CummNVRTCModuleBase(tv.NVRTCModule):
+
     def __init__(self,
                  code: str,
                  headers: Optional[Dict[str, str]] = None,
                  opts: Optional[List[str]] = None,
                  program_name: str = "kernel.cu",
                  name_exprs: Optional[List[str]] = None,
                  name_to_meta: Optional[Dict[str, tv.NVRTCKernelMeta]] = None,
@@ -208,14 +280,15 @@
         super().__init__(code,
                          headers,
                          opts,
                          program_name=program_name,
                          name_exprs=name_exprs,
                          name_to_meta=name_to_meta,
                          cudadevrt_path=cudadevrt_path)
+        self.code = code
         # extract meta data from ptx
         self.kernel_metas = list(name_to_meta.values())
         ptx = self.program.ptx()
         const_values: Dict[str, int] = {}
         for line in ptx.split("\n"):
             line = line.strip()
             if line.startswith(".global .align"):
@@ -262,158 +335,196 @@
                     const_values[name] = int(parts[-1].replace(";", " "))
                 elif len(parts) == 5:
                     name = cufilt(name[:-1])
                     if not name:
                         continue
                     const_values[name] = 0
 
-
         self.const_values = const_values
 
     @classmethod
     def from_params(cls, params: NVRTCModuleParams):
-        return cls(params.code,
-                params.headers,
-                params.opts,
-                name_exprs=params.name_exprs,
-                name_to_meta=params.name_to_meta,
-                cudadevrt_path=params.cudadevrt_path)
+        try:
+            return cls(params.code,
+                       params.headers,
+                       params.opts,
+                       name_exprs=params.name_exprs,
+                       name_to_meta=params.name_to_meta,
+                       cudadevrt_path=params.cudadevrt_path)
+        except RuntimeError:
+            print("Build Error. Kernel Code:\n{}".format(params.debug_code))
+            raise
 
     @property
     def kernels(self):
         assert self.name_to_meta is not None
         return list(self.name_to_meta.keys())
 
+
 class CummNVRTCModule(CummNVRTCModuleBase):
+
     def __init__(self,
                  cus: List[pccm.Class],
                  namespace_root: Optional[Union[str, Path]] = None,
                  verbose: bool = False,
                  cudadevrt_path: str = "",
                  custom_names: Optional[List[str]] = None,
                  verbose_path: str = "",
-                 std: str = "c++14") -> None:
-        mod_params = create_nvrtc_code(cus, namespace_root, cudadevrt_path, custom_names, std)
+                 std: str = "c++14",
+                 add_arch_flag: bool = True) -> None:
+        mod_params = create_nvrtc_code(cus, namespace_root, cudadevrt_path,
+                                       custom_names, std, add_arch_flag=add_arch_flag)
         if verbose:
             if verbose_path:
                 verbose_path_p = Path(verbose_path)
                 for k, v in mod_params.headers.items():
                     code_path = verbose_path_p / k
                     code_path.parent.mkdir(exist_ok=True, parents=True)
                     with code_path.open("w") as f:
                         f.write(v)
             else:
                 for k, v in mod_params.headers.items():
                     print(k)
                     print(v)
-        super().__init__(mod_params.code,
-                         mod_params.headers,
-                         mod_params.opts,
-                         name_exprs=mod_params.name_exprs,
-                         name_to_meta=mod_params.name_to_meta,
-                         cudadevrt_path=cudadevrt_path)
+        try:
+            super().__init__(mod_params.code,
+                            mod_params.headers,
+                            mod_params.opts,
+                            name_exprs=mod_params.name_exprs,
+                            name_to_meta=mod_params.name_to_meta,
+                            cudadevrt_path=cudadevrt_path)
+        except RuntimeError:
+            print("Build Error. Kernel Code:\n{}".format(mod_params.debug_code))
+            raise
+
+
+def _array_struct_nested(shape, type):
+    if shape:
+
+        class Array(ctypes.Structure):
+            _fields_ = (("array_",
+                         _array_struct_nested(shape[1:], type) * shape[0]), )
+
+        return Array
+    else:
+        return type
+
 
 class CummLLVMModule:
+
     def __init__(self,
                  cus: List[pccm.Class],
                  namespace_root: Optional[Union[str, Path]] = None,
                  verbose: bool = False,
                  verbose_path: str = "",
-                 std: str = "c++17") -> None:
-        self.mod_params: NVRTCModuleParams = create_nvrtc_code(cus, namespace_root, "", [], std, cpu_code=True)
+                 std: str = "c++14") -> None:
+        self.mod_params: NVRTCModuleParams = create_nvrtc_code(cus,
+                                                               namespace_root,
+                                                               "", [],
+                                                               std,
+                                                               cpu_code=True)
         if verbose:
             if verbose_path:
                 verbose_path_p = Path(verbose_path)
                 for k, v in self.mod_params.headers.items():
                     code_path = verbose_path_p / k
                     code_path.parent.mkdir(exist_ok=True, parents=True)
                     with code_path.open("w") as f:
                         f.write(v)
             else:
                 for k, v in self.mod_params.headers.items():
                     print(k)
                     print(v)
         self._llvm_mod: Optional[Any] = None
         self._llvm_engine: Optional[Any] = None
-        self._use_llvm_bit_code = True
+        self._use_llvm_bit_code = False
 
         self.name_to_meta = self.mod_params.name_to_meta
 
     def load(self):
         import llvmlite.binding as llvm
         _lazy_load_llvm()
         # use clang++ to get ir
         opts = self.mod_params.opts
-
+        _lazy_load_lib_for_llvm(self.mod_params.libraries,
+                                self.mod_params.libpaths)
         with tempfile.TemporaryDirectory() as fdir:
             inc_dir = Path(fdir) / "include"
-        
             for k, v in self.mod_params.headers.items():
                 code_path = Path(inc_dir) / k
                 code_path.parent.mkdir(exist_ok=True, parents=True)
                 with code_path.open("w") as f:
                     f.write(v)
-            print(inc_dir)
+            # print(inc_dir)
             out_name = Path(fdir) / "ir.ll"
             with tempfile.NamedTemporaryFile("w", suffix=".cc") as f2:
                 f2.seek(0)
                 f2.write(self.mod_params.code)
                 f2.flush()
-                # print(["clang++", "-S", "-emit-llvm", f2.name, *opts, "-o", f.name])
-                # subprocess.check_output(["clang++", "-S", "-emit-llvm", "/home/yy/Projects/cumm/cumm/nvrtc/wtf.cc", "-o", "wtf.o"])
-                # breakpoint()
-                print(opts)
+                # -fno-use-cxa-atexit:
+                # https://groups.google.com/g/llvm-dev/c/WUMwGnaaaSc
+                # https://stackoverflow.com/questions/68869921/lli-is-generating-run-time-error-for-clang-generated-ir-while-the-generated-ex
                 if self._use_llvm_bit_code:
-                    subprocess.check_output(["clang++", "-emit-llvm", "-c", f2.name, *opts, "-O3", "-I", str(inc_dir), "-o", str(out_name)])
+                    subprocess.check_output([
+                        "clang++", "-emit-llvm", "-fno-use-cxa-atexit", "-c",
+                        f2.name, *opts, "-O3", "-I",
+                        str(inc_dir), "-o",
+                        str(out_name)
+                    ])
                 else:
-                    subprocess.check_output(["clang++", "-S", "-emit-llvm", "-c", f2.name, *opts, "-O3", "-I", str(inc_dir), "-o", str(out_name)])
-                breakpoint()
-
-                # breakpoint()
-                # print(1)
+                    subprocess.check_output([
+                        "clang++", "-S", "-emit-llvm", "-fno-use-cxa-atexit",
+                        "-c", f2.name, *opts, "-O3", "-I",
+                        str(inc_dir), "-o",
+                        str(out_name)
+                    ])
             # read ir and pass to llvmlite
             with out_name.open("rb" if self._use_llvm_bit_code else "r") as f:
                 llvm_ir = f.read()
         # print(llvm_ir)
-        # breakpoint()
+        # with open("/home/yy/Projects/cumm/build/dev_llvm_ir.ll", "w") as f:
+        #     f.write(llvm_ir)
+        assert LLVM_GLOBAL_ENGINE is not None
+        # self._llvm_engine = create_execution_engine()
+        self._llvm_engine = LLVM_GLOBAL_ENGINE
 
-        self._llvm_engine = create_execution_engine()
         if self._use_llvm_bit_code:
             self._llvm_mod = compile_bitcode(self._llvm_engine, llvm_ir)
         else:
             self._llvm_mod = compile_ir(self._llvm_engine, llvm_ir)
-
         # breakpoint()
-    
+
     def _get_loaded_llvm_mod(self):
-        assert self._llvm_mod is not None 
+        assert self._llvm_mod is not None
         return self._llvm_mod
 
     def _get_loaded_llvm_engine(self):
-        assert self._llvm_engine is not None 
+        assert self._llvm_engine is not None
         return self._llvm_engine
 
     def run_kernel(self, name: str, launch: tv.LaunchParam,
                    *args: Union[Tensor, int, float, List[int], List[float],
                                 Tuple[float, ...], Tuple[int, ...]]):
         if self._llvm_mod is None:
             self.load()
-        metas: List[tv.NVRTCArgMeta] = [tv.NVRTCArgMeta(False, -1, [])] * len(args)
+        metas: List[tv.NVRTCArgMeta] = [tv.NVRTCArgMeta(False, -1, [])
+                                        ] * len(args)
         if self.name_to_meta:
             assert name in self.name_to_meta, f"can't find your kernel {name}, available: {self.name_to_meta.keys()}"
             assert len(args) == len(self.name_to_meta[name].args)
-            metas = self.name_to_meta[name].arg_metas        
+            metas = self.name_to_meta[name].arg_metas
         from pccm.builder.inliner import PCCM_INLINE_FUNCTION_NAME
         mod = self._get_loaded_llvm_mod()
         func_mangle_name = ""
         for func in mod.functions:
             if PCCM_INLINE_FUNCTION_NAME in func.name:
                 func_mangle_name = func.name
         assert func_mangle_name != ""
-        func_ptr = self._get_loaded_llvm_engine().get_function_address(func_mangle_name)
+        func_ptr = self._get_loaded_llvm_engine().get_function_address(
+            func_mangle_name)
         # breakpoint()
         assert func_ptr != 0, f"get function {name} failed."
         # cfunc = ctypes.CFUNCTYPE(c_double, c_double, c_double)(func_ptr)
         cfunc_types = []
         cfunc_args = []
         for arg, meta in zip(args, metas):
             if meta.valid:
@@ -434,30 +545,43 @@
                     else:
                         cfunc_args.append(arg.byte_pointer())
                     continue
                 else:
                     # we can't ensure arg isn't tv::Tensor.
                     if not isinstance(arg, Tensor):
                         if not meta.is_scalar:
+                            assert meta.count is None, "don't support non-scalar array"
                             assert not isinstance(arg, Tensor)
-                            dtype = tv.get_npdtype_from_tvdtype(meta.simple_type)
+                            dtype = tv.get_npdtype_from_tvdtype(
+                                meta.simple_type)
                             arg_array = np.array(arg, dtype=dtype)
                             if not arg_array.shape:
                                 arg_array = arg_array.reshape(1)
-                            assert list(arg_array.shape) == meta.shape
-                            ctype = np.ctypeslib.as_ctypes_type(dtype) * arg_array.size
-                            cfunc_args.append(ctype(*arg_array.reshape(-1)))
-                            # auto dtype cast
-                            # TODO prevent floats assigned to ints
+                            assert list(arg_array.shape
+                                        ) == meta.shape, f"{arg_array.shape}"
+                            ctype = _array_struct_nested(
+                                arg_array.shape,
+                                np.ctypeslib.as_ctypes_type(dtype))
+                            cfunc_args.append(
+                                ctype.from_buffer_copy(memoryview(arg_array)))
                             cfunc_types.append(ctype)
                             continue
                         else:
+                            # scalar may have count
                             assert not isinstance(arg, Tensor)
-                            dtype = tv.get_npdtype_from_tvdtype(meta.simple_type)
+                            dtype = tv.get_npdtype_from_tvdtype(
+                                meta.simple_type)
                             ctype = np.ctypeslib.as_ctypes_type(dtype)
+                            if meta.count is not None:
+                                assert isinstance(
+                                    arg, list
+                                ), f"only support np.ndarray -> type[] format, {type(arg)}"
+                                ctype = ctype * meta.count
+                                # arg = ctype.from_buffer_copy(memoryview(arg_array))
+                                arg = ctype(*arg)
                             cfunc_types.append(ctype)
                             cfunc_args.append(arg)
                             continue
             # meta isn't valid, use regular dtypes.
             if isinstance(arg, (int, float)):
                 ctype = ctypes.c_float
                 if isinstance(arg, int):
@@ -482,10 +606,15 @@
                 else:
                     cfunc_args.append(arg.byte_pointer())
         # print(cfunc_types, cfunc_args, func_ptr)
         # breakpoint()
         cfunc_type = ctypes.CFUNCTYPE(ctypes.c_int, *cfunc_types)(func_ptr)
         res = cfunc_type(*cfunc_args)
         # print(res)
+        if res != 0:
+            raise RuntimeError(
+                "LLVM run failed. see error logged to stdout before.")
+        return res
 
-        return res 
 
+if __name__ == "__main__":
+    print(_array_struct_nested([4, 4], ctypes.c_float))
```

## cumm/tensorview/__init__.py

```diff
@@ -11,14 +11,15 @@
 # WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 # See the License for the specific language governing permissions and
 # limitations under the License.
 
 import contextlib
 from dataclasses import dataclass
 from enum import Enum
+import enum
 from functools import partial
 from typing import Callable, Dict, List, Optional, Tuple, Union
 
 import numpy as np
 from pccm import Argument
 from pccm.middlewares.pybind import (TemplateTypeStmt,
                                      _simple_template_type_parser)
@@ -78,40 +79,48 @@
     "unsigned int": uint32,
     "__half": float16,
     "tv::half_t": float16,
     "tv::bfloat16_t": bfloat16,
     "at::Half": float16,
 }  # type: Dict[str, int]
 
-_VALID_CONTAINER_TYPES = {"tv::array", "std::array"}
+_VALID_CONTAINER_TYPES = {"tv::array", "std::array", "tv::TensorView"}
+
+class NVRTCArgBaseType(enum.IntEnum):
+    Scalar = 0
+    Pointer = 1
+    Array = 2
+    TensorView = 3
 
 def div_up(a, b):
     return (a + b - 1) // b 
 
 @dataclass
 class NVRTCArgMeta:
+    base_type: NVRTCArgBaseType
     valid: bool
     simple_type: int
     shape: List[int]
 
     is_simple_ptr: bool = False
     is_scalar: bool = False
+    count: Optional[int] = None
 
 
 class NVRTCKernelMeta:
     def __init__(self, name: str, ns: str, args: List[Argument]):
         self.name = name
         self.ns = ns
         self.args = args
         self.arg_types = [
             _simple_template_type_parser(a.type_str, {}) for a in args
         ]
         self.simple_types: List[Optional[int]] = []
         self.arg_metas: List[NVRTCArgMeta] = []
-        for meta in self.arg_types:
+        for arg, meta in zip(args, self.arg_types):
             simple_tv_type = -1
             is_simple_ptr = False
             valid = meta.name != ""
             shape: List[int] = []
             if valid and not meta.is_ptr:
                 # determine scalar type
                 cur_meta = meta
@@ -129,19 +138,27 @@
                     shape.append(length)
                     cur_meta = cur_meta.args[0]
             elif valid and meta.is_ptr:
                 if meta.name in _SIMPLE_TYPES_TO_TV_DTYPE:
                     is_simple_ptr = True
                     simple_tv_type = _SIMPLE_TYPES_TO_TV_DTYPE[meta.name]
             is_scalar = len(shape) == 0
+            base_type = NVRTCArgBaseType.Scalar if is_scalar else NVRTCArgBaseType.Array
+            if meta.name == "tv::TensorView":
+                base_type = NVRTCArgBaseType.TensorView
+                assert len(shape) == 1, "only support 1d tensorview (e.g. tv::Tensorview<float, N>)"
             if len(shape) == 0:
                 shape = [1]
             # shape = shape[::-1]
             self.arg_metas.append(
-                NVRTCArgMeta(valid, simple_tv_type, shape, is_simple_ptr, is_scalar))
+                NVRTCArgMeta(base_type, valid, simple_tv_type, shape, is_simple_ptr, is_scalar))
+            if isinstance(arg.array, int):
+                self.arg_metas[-1].count = arg.array
+            elif isinstance(arg.array, str):
+                raise NotImplementedError("don't support string array", arg)
 
     def __repr__(self) -> str:
         return f"NVRTCKernelMeta[name={self.name},ns={self.ns},args={self.arg_metas}]"
 
 class LaunchParam:
     def __init__(self,
                  blocks: Union[Tuple[int, ...], List[int]],
@@ -227,15 +244,15 @@
             name = self.get_lowered_name(name)
         return self._mod.run_kernel(name, launch.blocks, launch.threads,
                                     launch.smem, launch.stream, list(args))
 
     def run_kernel(self, name: str, launch: LaunchParam,
                    *args: Union[Tensor, int, float, List[int], List[float],
                                 Tuple[float, ...], Tuple[int, ...]]):
-        metas: List[NVRTCArgMeta] = [NVRTCArgMeta(False, -1, [])] * len(args)
+        metas: List[NVRTCArgMeta] = [NVRTCArgMeta(NVRTCArgBaseType.Scalar, False, -1, [])] * len(args)
         if self.name_to_meta:
             assert name in self.name_to_meta, f"can't find your kernel {name}, available: {self.name_to_meta.keys()}"
             assert len(args) == len(self.name_to_meta[name].args)
             metas = self.name_to_meta[name].arg_metas
         if self._name_exprs:
             name = self.get_lowered_name(name)
         kernel_args: List[Tuple[Tensor, int]] = []
@@ -250,14 +267,27 @@
                         expected_dtype = get_npdtype_from_tvdtype(
                             meta.simple_type)
                         raise ValueError(
                             f"your tensor {arg.shape}|{cur_dtype}"
                             f" dtype not equal to {expected_dtype}")
                     kernel_args.append((arg, _NVRTCModule.kTensor))
                     continue
+                elif meta.base_type == NVRTCArgBaseType.TensorView:
+                    if not isinstance(arg, Tensor):
+                        raise ValueError("your arg must be tensor")
+                    assert arg.ndim == meta.shape[0],f"your tensor ndim {arg.ndim} must equal to f{meta.shape[0]}"
+                    if not arg.dtype == meta.simple_type:
+                        cur_dtype = get_npdtype_from_tvdtype(arg.dtype)
+                        expected_dtype = get_npdtype_from_tvdtype(
+                            meta.simple_type)
+                        raise ValueError(
+                            f"your tensor {arg.shape}|{cur_dtype}"
+                            f" dtype not equal to {expected_dtype}")
+                    kernel_args.append((arg, _NVRTCModule.kTensorView))
+                    continue
                 else:
                     # we can't ensure arg isn't tv::Tensor.
                     if not isinstance(arg, Tensor):
                         assert not isinstance(arg, Tensor)
                         dtype = get_npdtype_from_tvdtype(meta.simple_type)
                         arg_array = np.array(arg, dtype=dtype)
                         if not arg_array.shape:
```

## Comparing `cumm_cu120-0.4.8.dist-info/LICENSE` & `cumm_cu120-0.4.9.dist-info/LICENSE`

 * *Files identical despite different names*

## Comparing `cumm_cu120-0.4.8.dist-info/METADATA` & `cumm_cu120-0.4.9.dist-info/METADATA`

 * *Files 0% similar despite different names*

```diff
@@ -1,10 +1,10 @@
 Metadata-Version: 2.1
 Name: cumm-cu120
-Version: 0.4.8
+Version: 0.4.9
 Summary: CUda Matrix Multiply library
 Home-page: https://github.com/FindDefinition/cumm
 Author: Yan Yan
 Author-email: yanyan.sub@outlook.com
 License: MIT
 Classifier: License :: OSI Approved :: MIT License
 Classifier: Programming Language :: Python
```

## Comparing `cumm_cu120-0.4.8.dist-info/RECORD` & `cumm_cu120-0.4.9.dist-info/RECORD`

 * *Files 4% similar despite different names*

```diff
@@ -1,16 +1,16 @@
 cumm/__init__.py,sha256=B43maQ1Qm4GxdDkmCyJqx7DUPs4tVCOdB6RasVndC64,1340
-cumm/__version__.py,sha256=NBKZ8rZ08tbA9ihNAt8XjKsBic5G-NJ2m6-nps3bbIQ,23
-cumm/common.py,sha256=fzc7Ecx_N32NuDXUmbagWc5Jl6iigUtalinveZzCy2M,27857
+cumm/__version__.py,sha256=Kzqf5fHfab3rLJIAbrkeQk13-YmfTH_qfP_PVGNigAo,23
+cumm/common.py,sha256=rwepnfHLBh-9TqB0TXmzfNcg1QK7zXgDX7aU_L9W0Lw,29533
 cumm/constants.py,sha256=AtBuh4S6gXpJIxOo5L0vpJXPyrVf7dY9ZbG0skmMF0k,1764
-cumm/core_cc.cp39-win_amd64.pyd,sha256=Myoa0xoybgcRiwjtcIO1O2t7OETDlV5ptE74GJXcMzw,1045504
+cumm/core_cc.cp39-win_amd64.pyd,sha256=Z0b52PlTMwRCJOf84rcuDGRdnLBXHNRrS-Vg2ctp7dw,1059328
 cumm/dtypes.py,sha256=rK-LRfaVEfYQoyLH6joNCGf6LwgR1iGrtyz0PJvsahg,5888
 cumm/inliner.py,sha256=bbQTy6pJMLFtgqKein4vxRPTaSSVZIDWMEwj5dNUt2E,6575
-cumm/tensorview_bind.py,sha256=m3MwhcKDYBLeXIQpHgDD4QtzchS5vypYOYzMdnj9Nmw,41030
-cumm/tensorview_bind_anno.pyi,sha256=LFQ3uL80PvfuMJ_q892yiVsJd7gcZHIiwYZB_8yOCvE,18470
+cumm/tensorview_bind.py,sha256=m_0ybHcyuvQCHADAncxUEDk7j7aTajOstWpnpXr2Snk,41098
+cumm/tensorview_bind_anno.pyi,sha256=91ahm3eLOYMZ-VZA8IGkNptHnNuJy4qQeNtZ18wQoB4,18474
 cumm/cmds/__init__.py,sha256=gchSVt8ily9AMHWH99CnIMpPLPO1F9EOCJOOUVOJN_g,589
 cumm/cmds/include_path/__init__.py,sha256=gchSVt8ily9AMHWH99CnIMpPLPO1F9EOCJOOUVOJN_g,589
 cumm/cmds/include_path/__main__.py,sha256=zQ0t7DBcqag1sYB5r6b0r1KUdZJ_2vFC_aIgdEVw_ys,121
 cumm/conv/__init__.py,sha256=GYjax4PvCDVajX5rT03pcgt4kU6IHNSQK34vVTNHu8c,584
 cumm/conv/algo.py,sha256=iKD6bPN-ZBFCmAyiRJ1tPIL3ThBndtPVXLn65LpMYU0,3125
 cumm/conv/bases.py,sha256=HaK5uxygh3k9mv_VjhNl9_sgBCeaW7PV7N_A5uwCNyY,3634
 cumm/conv/input_iters.py,sha256=BOCeyodHYwENeSRXo4NMi2zKWwzXFi3YSvK-TWswOGY,123453
@@ -24,15 +24,15 @@
 cumm/conv/algospec/__init__.py,sha256=oaaUUW6zb8k-RV022asNtMLZfnXExGr5MMxFaThKJx8,690
 cumm/conv/algospec/all.py,sha256=kMPYycZHhb1ld9b5T4wcgnp0jNXo6jcalYcpL6Icxis,1263
 cumm/conv/algospec/core.py,sha256=cBy0FdvSa1scSKcD5h_TD4Yx8XCCPd4nU_LyoiYqla8,734
 cumm/conv/algospec/simt.py,sha256=HDqF-MwoDoeoHEE7y3haN2l4rf39jny2InntHCXWJtE,10008
 cumm/conv/algospec/turing.py,sha256=EgGEseZsND_Iq4uf1PFReN9_f9DUeLFrpGoj6NXXW5g,12175
 cumm/conv/algospec/volta.py,sha256=SkFRs7WO9_Tq5gYeVXHAk_Q0TKjkR1iQ9IzBO2oCag0,10372
 cumm/core_cc/__init__.pyi,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
-cumm/core_cc/tensorview_bind.pyi,sha256=xzNg7FDWqK7Qi-GMglYC06MxzhHu8bNiRdgXlhGbdBE,18683
+cumm/core_cc/tensorview_bind.pyi,sha256=e8EDM9sUXF1gWM9Vsn-AxAKs5oc1Sns4F3xD7Wp3b1c,18687
 cumm/core_cc/csrc/__init__.pyi,sha256=47DEQpj8HBSa-_TImW-5JCeuQeRkm5NMpJWZG3hSuFU,0
 cumm/core_cc/csrc/arrayref.pyi,sha256=Qu5ApCYAAdsE14Xlr26UqQFQqAL9mn_U4pX1FvDGntk,2888
 cumm/csrc/__init__.py,sha256=GYjax4PvCDVajX5rT03pcgt4kU6IHNSQK34vVTNHu8c,584
 cumm/csrc/arrayref.py,sha256=HeO6JbIthLqU0axcJrw9Up_CWRf6i_ODbXEr3rdvpk4,17946
 cumm/cudasim/__init__.py,sha256=uKYTkDpY8Q0uNYXFVaxSlMi63Fy3CeHp2HnoiS1RO5c,8173
 cumm/cudasim/checkers.py,sha256=6PvMYdxmx72XUo9B0AB0j5D7Rt_M8SXFUIFLCPqYAjs,1668
 cumm/cudasim/debug.py,sha256=igQeAcn5ZuDT_QXdiSjIA0yGVl5bBizueHVAMzlsSww,1679
@@ -97,36 +97,36 @@
 cumm/gemm/outputs/__init__.py,sha256=ZSOJBI-g1tOffsxC4Lv9bEZst6HsVvTrAO3Wx9QdwaA,19506
 cumm/gemm/wmma/__init__.py,sha256=4_EamAKQ9F47m0yo0ifrorc91zhOCUnGcrF2TDtf8IQ,621
 cumm/gemm/wmma/simt.py,sha256=l2R-ty_1wUcO12kj0xuGiIRz_lFSlv0D_owZ7uIOofY,21856
 cumm/gemm/wmma/turing.py,sha256=VYPv128XjcBFKd9a20XLZTNmwYiq7LVuyR7c9QMgSPg,7428
 cumm/gemm/wmma/volta.py,sha256=P6tUDak0vTAAtCa-C9g4_V7y9wgS-tCwoq9eSWf0RhM,7711
 cumm/gemmv2/__init__.py,sha256=gchSVt8ily9AMHWH99CnIMpPLPO1F9EOCJOOUVOJN_g,589
 cumm/include/tensorview/cc17.h,sha256=_wccACbGp5x3teDv8PJBlCp4JLwRU800V8byDcj_XcM,36
-cumm/include/tensorview/check.h,sha256=UY33g93X5AGMbCeViCaxsoqH7kRRYHYJBE7SsmxDdzY,2175
+cumm/include/tensorview/check.h,sha256=X752uByyeLiflsVHImn7HXNJ_aJykILo2b1rWFoAMA0,2187
 cumm/include/tensorview/common.h,sha256=VRcv3y_6FUkcbG2VrPEHvKt4_nKOCeEJU3DCydIXnrc,40
 cumm/include/tensorview/context.h,sha256=tUKXSXfRF-YQ0rRKG06nSG1Yr6W7jgZbezTYothBS1U,40
 cumm/include/tensorview/cuda_utils.h,sha256=jpUoElZfy0Zp0-bQf2YCp3x-binHkUxWL_MQXiaGJdI,38
 cumm/include/tensorview/device_ops.h,sha256=Z3KAg_c5n83WLOPduYkJvOcwLpLa-y_-Sk990o7ebpc,43
 cumm/include/tensorview/dtypes.h,sha256=FOo1jbAoqOZA5ZpApe7mjw4R1mU63BaXTZb6FF6Ev5o,12293
 cumm/include/tensorview/kernel_utils.h,sha256=fvEEm6Er26krOYCkIDfXOI0MshVjvEY8Nh05y4kc4fM,56
 cumm/include/tensorview/mp_helper.h,sha256=Dl9tSpJ4y8JCVuGWrh2yYSUtimVt5lxqapN4ZgSsgXw,53
 cumm/include/tensorview/prettyprint.h,sha256=3Cp6CiDCns2vQIjE4fVR_Pg05-v7Eq8nDLSyvPbVfvE,16874
 cumm/include/tensorview/pybind.h,sha256=bIT3wZsvVVjKsIbS5wo7_4n0zZmQLMVnDQ4hgOKrNKs,9916
 cumm/include/tensorview/pybind_utils.h,sha256=G7OuyyZEAvam4b3D_pJS3w3lNww4qBmm-9nOr33_wfM,33
 cumm/include/tensorview/simple_ops.h,sha256=FDiKaEuHsa_gxxYRGvW1owX15Yuckq3lEdZpb3tKBUk,3632
-cumm/include/tensorview/tensor.h,sha256=2zxMU-YmOZAdxlzzfBDR-zi2DlFRxQlf09gg32igFKI,63147
-cumm/include/tensorview/tensorview.h,sha256=naBaPOUEXDO6e9CmPAn5Ol2k8DiAEduNIZNm0s6lvfM,38575
+cumm/include/tensorview/tensor.h,sha256=0FXuQRyj_5dsGqMY-lYg5Ka_Ecl2-p8M3h8qUMdjQiI,63520
+cumm/include/tensorview/tensorview.h,sha256=zgLBZDAbZaSrwC-hZJyNHBcSklpGnr8mZnO4OvGT3Mk,38851
 cumm/include/tensorview/tools.h,sha256=EYYZMGNN8xXKtjGTgS3dhKzh_4hOXXUFAoGFatxnsYs,2163
 cumm/include/tensorview/torch_utils.h,sha256=BPoVivt9SIVVTIfP8-OB5fDsWH1lqAM9xeBZvmFLr60,8239
 cumm/include/tensorview/contexts/core.h,sha256=gUxp4hrwEqCxK8sdp_iANcG6V1f3UgtmDjDcUeycXyg,4884
 cumm/include/tensorview/contexts/cuda_blas.h,sha256=By3moSqZR8qSdt0KjRtfiVwRQpth5uvKxMtBWWIuuF4,2044
 cumm/include/tensorview/core/all.h,sha256=-VcarXOhqV5IsUtJZsW02-ViTtBeT1XdA57KsOTMu7Y,802
 cumm/include/tensorview/core/array.h,sha256=AniZ979NFFPQz9wcqRH6OnAa6isHkrXxawyJuVvXFv4,27833
 cumm/include/tensorview/core/cc17.h,sha256=Z_D_DFrNAo5ORwKZJl4TOP8dqFSyZ9Ap-DoMrRVW-1I,15394
-cumm/include/tensorview/core/common.h,sha256=ZzMGpLpn147giTOHScowu3AQgsdBX92rtVUYwLTmgsU,13082
+cumm/include/tensorview/core/common.h,sha256=HOK2uRXAM1kZLXGssJerRf8JZAkEFkoCXHS44o2FqAY,13287
 cumm/include/tensorview/core/const_ops.h,sha256=NzdeV3BCiZq7CI_16SZCD7XRCwRfE-JG48HWzV3m1cs,884
 cumm/include/tensorview/core/const_string.h,sha256=COjPs10QBPLTjyK2dP5zBMJjvysfbH1wxF9YzQX164M,3925
 cumm/include/tensorview/core/defs.h,sha256=KZTSrEDX3blzl3mh6_8SsDIqS8SAc2sda0vlJMj2Thg,2872
 cumm/include/tensorview/core/mp_helper.h,sha256=vYCn4yVZOsca04FbHZKG5edPSaG4njJPFDIsXFaKeko,24509
 cumm/include/tensorview/core/nvrtc_std.h,sha256=_5ZTNXFWJQniNVSQPlnm7sXAnvcfgmWKx8pUeq0qAmI,1186
 cumm/include/tensorview/core/printf2.h,sha256=-c9aqDgIKfvIkrlXLhYIVyMJxsDMZpZ3fZIS2MCWpDA,8260
 cumm/include/tensorview/core/vecarray.h,sha256=Bgg7fLvwRcRvHdgYWiShVMQwU_mzmT1lXxxwbXWYY4o,6514
@@ -134,24 +134,24 @@
 cumm/include/tensorview/core/arrayops/linalg.h,sha256=nUyOVcKmqi6jaMx-OPrpngpOR8iq3huykq6tgQGeC3M,34508
 cumm/include/tensorview/core/arrayops/mathbase.h,sha256=zO0mKJyO-TcfFfrWbqWFrKgwWFd6kDGFj_PtFmVFLkE,23355
 cumm/include/tensorview/core/arrayops/simple.h,sha256=sjpJt-lbAEkK94Ozr5rvOS7Y0FVcSXN3mzH_GDPD2rU,5579
 cumm/include/tensorview/core/nvrtc/core.h,sha256=h4qG250ort68GITIZrarnJj4pU737NQXmXr0cI1_iAA,1951
 cumm/include/tensorview/core/nvrtc/limits.h,sha256=d74fayKx52wGvUuPYCi8gBYHSF6f3NLYatjZx_so64Q,38943
 cumm/include/tensorview/core/nvrtc/runtime_include.h,sha256=Kw4M0V4UKOM9wo1yulb5KjN2MTngOVSaS2XIZNBxaSQ,85
 cumm/include/tensorview/core/nvrtc/tuple.h,sha256=ru4w2kxqHYX6tHX7cR0ToQpuP9aD_DclYW2rCK8mHZk,3126
-cumm/include/tensorview/core/nvrtc/type_traits.h,sha256=XCPpX8ymU9i1rGLCzzg0JV2p_DekMIDr6cRePQbHx7g,14509
+cumm/include/tensorview/core/nvrtc/type_traits.h,sha256=W9ScnNsJ2QMSK86FxDYx-6v3LEDt2HuVELqswMbtEJQ,15490
 cumm/include/tensorview/cuda/all.h,sha256=wQoOTBx7Q-dvAozDZkz5baTJr8bqrJ9ORWInLzoxMvI,661
 cumm/include/tensorview/cuda/arch_defs.h,sha256=jAbCstVx7RrP_ussYSN5kbsGWNuJaoGRx9pLT2hQQDs,1008
 cumm/include/tensorview/cuda/device_ops.h,sha256=gln8aocSWR4J-W4A-SqQOTFFF2vp2uHvbS6dx6dttnk,2954
 cumm/include/tensorview/cuda/driver.h,sha256=XSyH_s0xrL17blLOhyAtxqPmtSAkm54N2AgXZNzKjO0,9497
 cumm/include/tensorview/cuda/driverops.h,sha256=67rioMrlalR1DcmYII8qlYewwizCodTHx9O7ueuV8GM,16164
 cumm/include/tensorview/cuda/kernel_all.h,sha256=s61ZbPv-d2f-K-V6d22NMENjm-SXRB1Uwe_TrU6Ene8,685
 cumm/include/tensorview/cuda/kernel_utils.h,sha256=3_tsWHZD5h-nBKimiM7CyRP4pDyPGzUSX3mZM7xVJG0,3917
 cumm/include/tensorview/cuda/launch.h,sha256=6GTEDTrTfmSA6CTR5ZVZNluyfsUn868S_kL79Q2qPpY,3612
-cumm/include/tensorview/cuda/nvrtc.h,sha256=uY7GNsvXyN2PxlA_dY6sJRgtcv6QnZ6j3uBgoBOExh0,19539
+cumm/include/tensorview/cuda/nvrtc.h,sha256=wJ7sI73v-dbfdHCHPB6za7yRk5tZuSzFTE-hTbLFplc,20406
 cumm/include/tensorview/gemm/constants.h,sha256=YiXpWKYtkKe7h9oMkeqgFjSQvNvUgmXmO1MZ1vId5BM,873
 cumm/include/tensorview/gemm/cutlass_compat.h,sha256=FrAy389lRvwYM6NIXzAtaUi3Q-eqFOdTmBIvgh3UrXs,1019
 cumm/include/tensorview/gemm/debug.h,sha256=fk5n7J_VzdHlzpIzRqGAQRF8p3CPYQsjb6jehAE4cC8,5823
 cumm/include/tensorview/gemm/arch/memory.h,sha256=RQhcclDxB6fpNnSAmyZyqtLCVINeJZF7igSgJ2Ajbh4,10006
 cumm/include/tensorview/gemm/arch/memory_sm75.h,sha256=PD9x8R1k353rTLIg5dJ6lX0S3P1raepPQZ3Rl5-lMcs,4899
 cumm/include/tensorview/gemm/arch/semaphore.h,sha256=_pGyXMTa0jWomBpJkKXc4QZ1K2DDo2JEz4FX4he2yG8,4023
 cumm/include/tensorview/gemm/arch/transpose.h,sha256=VEk6n35iWCsZN2SCYqBInpdpnhgCJ8nIEmgm0bc5K0I,4967
@@ -196,22 +196,22 @@
 cumm/include/tensorview/profile/cuda_profiler.h,sha256=kMwPwcmosccfKBsm5aCk6FagxbfXGWmgTLY0W578Y2E,12145
 cumm/include/tensorview/thirdparty/nlohmann/json.hpp,sha256=Ldjbcjz_PkQZjhTWA46mRD3GFxpWS7gs1u6B8O3DFuU,932454
 cumm/include/tensorview/thirdparty/tsl/robin_growth_policy.h,sha256=9OcrrLpU9rSnlTS1Z5R4i6N9uxzkTq6j4GlhHalgxf8,12179
 cumm/include/tensorview/thirdparty/tsl/robin_hash.h,sha256=thVKrgfvYXgzgNwtHTXcTyW6JAg2ONFnWkvg2ey30PY,55430
 cumm/include/tensorview/thirdparty/tsl/robin_map.h,sha256=rf0ik-d09LzEoj-w5oAkPGbgKzdeHKWN_JhVFdYe1rQ,29219
 cumm/include/tensorview/thirdparty/tsl/robin_set.h,sha256=HMuCZQugjGq867RlvQrGTBJT1OPz_dok2iER_KobUKw,24253
 cumm/include/tensorview/utility/tuplehash.h,sha256=JhMYsYmFOwkQnyAq1uKZN06r5Toj3FoNwTL72fe7juQ,1416
-cumm/inliner/__init__.py,sha256=5lXOzWGbbUbuXhCBStZ8AFHlrGjS7FNDfyf2CLtZKhA,17061
-cumm/nvrtc/__init__.py,sha256=_HlIlCLA-JAUE0v9m-CRrj0ImGvJuSmvF5oAnIdLVqE,20101
+cumm/inliner/__init__.py,sha256=jECxnor75UMbGKXA5E8LghjyZHS5XIVWCYJ9pHXrof4,21726
+cumm/nvrtc/__init__.py,sha256=2IkAzDU0vwcfpM0eOrv0V2iGJdTzTnNV9zANFTcCCFo,25379
 cumm/nvrtc/dev.py,sha256=pLTK4SChEleD0sT794ID8cJna90ozSwVuTWLC26m9cA,1240
 cumm/services/__init__.py,sha256=gchSVt8ily9AMHWH99CnIMpPLPO1F9EOCJOOUVOJN_g,589
 cumm/services/nvrtc.py,sha256=MsKRRowubNU-vn1DtGjWIAsaFtj23W4DJ5NpNF5Zp-M,1041
-cumm/tensorview/__init__.py,sha256=BM2WXGwIHfu6aXhy8bWgAsql8yOYAdDu4A94UdPuVQg,21260
+cumm/tensorview/__init__.py,sha256=Fpcx3F4yZiHHa6pAZZ7jYZv45sTFx8lVE_j7-u3Fbhc,22874
 cumm/tensorview/creator.py,sha256=7S8JeWVkPGdoDdE8JHWAP_cc3OON9OHHo3VU5VH5Ys0,2657
 cumm/tensorview/gemm.py,sha256=dhAfjzV1oC-SuA83Om_iNeJuhICcI9sw0BzvTxcVcZU,1038
 cumm/tensorview/tvio.py,sha256=yr15Pguc7UFxpkrxDkF4flWPqW1zkEb-p31UL9ohalY,9460
 cumm/tensorview/utils.py,sha256=zIDcaahSybHljoq0NSjshQsuQ_wjynjfLHtytLhKcis,134
-cumm_cu120-0.4.8.dist-info/LICENSE,sha256=avsNsX_X8DivlhdY3rdZMScgWjRw2TrFgc23WNcl7QY,11536
-cumm_cu120-0.4.8.dist-info/METADATA,sha256=UCsVeEC-5pmsJZg3TylEaesUWOj5TAn77CCC8blZdW0,6392
-cumm_cu120-0.4.8.dist-info/WHEEL,sha256=eep6QWEFiQfg2wcclssb_WY-D33AnLYLnEKGA9Rn-VU,100
-cumm_cu120-0.4.8.dist-info/top_level.txt,sha256=uQC2tS-bGXW_4hTBRIZ_GD_EA8G_7herC1dJLhuewh0,13
-cumm_cu120-0.4.8.dist-info/RECORD,,
+cumm_cu120-0.4.9.dist-info/LICENSE,sha256=avsNsX_X8DivlhdY3rdZMScgWjRw2TrFgc23WNcl7QY,11536
+cumm_cu120-0.4.9.dist-info/METADATA,sha256=8AmF_Km-w1xO7KzlzPw-8XOxWMAQLT8tMDq83Xssx4c,6392
+cumm_cu120-0.4.9.dist-info/WHEEL,sha256=eep6QWEFiQfg2wcclssb_WY-D33AnLYLnEKGA9Rn-VU,100
+cumm_cu120-0.4.9.dist-info/top_level.txt,sha256=uQC2tS-bGXW_4hTBRIZ_GD_EA8G_7herC1dJLhuewh0,13
+cumm_cu120-0.4.9.dist-info/RECORD,,
```

